{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Information Retrieval\n",
    "## Instructions\n",
    "1. Students will form teams of three people each and submit a single homework for each team in the format - ID1_ID2_ID3.ipynb\n",
    "2. Groups of four are not allowed.\n",
    "2. **Do not write your names anywhere.**\n",
    "3. For the code part: \n",
    "> **Write your code only in the mentioned sections. Do not change the code of other sections**. Do not use any imports unless we say so.\n",
    "4. For theoretical questions, if any - write your answer in the markdown cell dedicated to this task, in **English**.\n",
    "\n",
    "\n",
    "#### Deviation from the aforementioned  instructions will lead to reduced grade\n",
    "---\n",
    "\n",
    "\n",
    "## Clarifications\n",
    "1. The same score for the homework will be given to each member of the team.  \n",
    "2. The goal of this homework is to test your understanding of the concepts presented in the lectures. \\\n",
    "If a topic was not covered in detail during the lecture, you are asked to study it online on your own. \n",
    "Anyhow, we provide here detailed explanations for the code part and if you have problems - ask.\n",
    "3. Questions can be sent to the forum, you are encouraged to ask questions but do so after you have been thinking about your question. \n",
    "4. The length of the empty gaps (where you are supposed to write your code) is a recommendation (the amount of space took us to write the solution) and writing longer code will not harm your grade. We do not expect you to use the programming tricks and hacks we used to make the code shorter.   \n",
    "Having said that, we do encourage you to write good code and keep that in mind - **extreme** cases may be downgraded.  \n",
    "We also encourage to use informative variable names - it is easier for us to check and for you to understand. \n",
    "\n",
    "For your convenience, , the code has a **DEBUG** mode that you may use in order to debug with toy data.  \n",
    "It is recommended to solve the code in that mode (with efficiency in mind) and then run the code on all the data.\n",
    "**Do not forget to file the HW with DEBUG == False**.\n",
    "\n",
    "Download the \"Lyrics\" dataset from Moodle and put it in the same directory your script is.\n",
    "\n",
    "\n",
    "5. We use Python 3.7 for programming.\n",
    "6. Make sure you have all the packages and functions used in the import section. Most of it is native to Anaconda Python distribution.\n",
    "\n",
    "### Have fun !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "from typing import List,Dict\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\maxpo\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\maxpo\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "from string import punctuation, ascii_lowercase\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug\n",
    "**you can change this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEBUG = True\n",
    "DEBUG = False\n",
    "\n",
    "\"\"\"\n",
    "Recommended to start with a small number to get a feeling for the preprocessing with prints (N_ROWS_FOR_DEBUG = 2)\n",
    "later increase this number for 5*10**3 in order to see that the code runs at reasonable speed, and change the CHUNK_SIZE accordinaly\n",
    "When setting Debug == False, our code implements bow.fit() in 15-20 minutes according to the tqdm progress bar. Your solution is not supposed to be much further than that.\n",
    "\"\"\"\n",
    "N_ROWS_FOR_DEBUG = 2\n",
    "CHUNCK_SIZE = 1 if DEBUG else 5*10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE_PATH = Path(\"lyrics.csv\")\n",
    "BOW_PATH = Path(\"bow.csv\")\n",
    "N_ROWS = N_ROWS_FOR_DEBUG if DEBUG else None\n",
    "tqdm_n_iterations = N_ROWS//CHUNCK_SIZE +1 if DEBUG else 363*10**3//CHUNCK_SIZE + 1\n",
    "COLS = [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Bag of words model\n",
    "### Implement the following methods:\n",
    "\n",
    "* `preprocess_sentence`: \n",
    "    * Lower case the word\n",
    "    * Ignores it if it's in the stopwords list\n",
    "    * Removes characters which are not in the allowed symbols\n",
    "    * Stems it and appends it to the output sentence\n",
    "    * Discards words with length <= 1\n",
    "    \n",
    "    \n",
    "* `update_counts_and_probabilities`: \n",
    "\n",
    "    * Update self.unigram count (the amount of time each word is in the text)\n",
    "    * Update self.bigram count (two consecutive word occurances)\n",
    "    * Update self.trigram count (three consecutive word occurances)\n",
    "    * Update inverted index: a dictionary with words as keys and the values is a dictionary - {'DocID' : word_count}   \n",
    "    \n",
    "* `compute_word_document_frequency`:\n",
    "\n",
    "   * For each word count the number of docs it appears in. For example , for the word 'apple' -\n",
    "$$\\sum_{i \\in docs} I(apple \\in doc_i), I := Indicator function$$\n",
    "\n",
    "\n",
    "* `update_inverted_index_with_tf_idf_and_compute_document_norm`:\n",
    "\n",
    "    * Update the inverted index (which currently hold word counts) with tf idf weighing. We will compute tf by dividing with the number of words in each document. \n",
    "    * As we want to calculate the document norm, incrementally update the document norm. pay attention that later we apply sqrt to it to finish the process.\n",
    "\n",
    "#### The result of this code is a bag of words model that already counts for TF-IDF weighing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "allowed_symbols = set(l for l in ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 73/73 [19:25<00:00, 15.96s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_sentence(sentence : str) -> List[str]:\n",
    "    output_sentence = []\n",
    "    for word in word_tokenize(sentence):\n",
    "        ### YOUR CODE HERE\n",
    "        _word = word.lower()  # lowercase\n",
    "        if (len(_word) > 1 and _word not in stop_words):  # initial check for word's length and not a stop word\n",
    "            cleaned = \"\"  # placeholder for the word without forbidden symbols\n",
    "            for ch in _word:\n",
    "                if ch in allowed_symbols:\n",
    "                    cleaned += ch\n",
    "            if cleaned and len(cleaned) > 1 and cleaned not in stop_words:  # if we still have a relevant word\n",
    "                _word = stemmer.stem(cleaned)  # stemming word\n",
    "                output_sentence.append(_word)  # adding processed word to final output\n",
    "        ### END YOUR CODE\n",
    "    return output_sentence\n",
    "\n",
    "\n",
    "def get_data_chuncks() -> List[str]:\n",
    "    for i ,chunck in enumerate(pd.read_csv(INPUT_FILE_PATH, usecols = COLS, chunksize = CHUNCK_SIZE, nrows = N_ROWS)):\n",
    "        chunck = chunck.values.tolist()\n",
    "        yield [chunck[i][0] for i in range(len(chunck))] \n",
    "\n",
    "class TfIdf:\n",
    "    def __init__(self):\n",
    "        self.unigram_count =  Counter()\n",
    "        self.bigram_count = Counter()\n",
    "        self.trigram_count = Counter()\n",
    "        self.document_term_frequency = Counter()\n",
    "        self.word_document_frequency = {}\n",
    "        self.inverted_index = {}\n",
    "        self.doc_norms = {}\n",
    "        self.n_docs = -1\n",
    "        self.sentence_preprocesser = preprocess_sentence\n",
    "        self.bow_path = BOW_PATH\n",
    "\n",
    "    def update_counts_and_probabilities(self, sentence :List[str],document_id:int) -> None:\n",
    "        sentence_len = len(sentence)\n",
    "        self.document_term_frequency[document_id] = sentence_len\n",
    "        for i,word in enumerate(sentence):\n",
    "            ### YOUR CODE HERE\n",
    "            self.unigram_count[word] += 1  # counting 1 word\n",
    "            if i < sentence_len - 1:  # we still have atleast another word after the current one \n",
    "                self.bigram_count[(word,sentence[i + 1])] += 1\n",
    "            if i < sentence_len - 2:  # we still have atleast 2 more words after the current one\n",
    "                self.trigram_count[(word,sentence[i + 1],sentence[i + 2])] += 1\n",
    "            if word not in self.inverted_index.keys():\n",
    "                self.inverted_index[word] = {document_id : 1}  # starting to count word's apperances in document\n",
    "            else:\n",
    "                if document_id not in self.inverted_index[word].keys():  # in case doc's id was not found\n",
    "                    self.inverted_index[word][document_id] = 1  # starting to count word's apperances in document\n",
    "                else:\n",
    "                    self.inverted_index[word][document_id] += 1  # adding word's apperance in document\n",
    "            ### END YOUR CODE\n",
    "        \n",
    "    def fit(self) -> None:\n",
    "        for chunck in tqdm(get_data_chuncks(), total = tqdm_n_iterations):\n",
    "            for sentence in chunck: #sentence is a song (string)\n",
    "                self.n_docs += 1 \n",
    "                if not isinstance(sentence, str):\n",
    "                    continue\n",
    "                sentence = self.sentence_preprocesser(sentence)\n",
    "                if sentence:\n",
    "                    self.update_counts_and_probabilities(sentence,self.n_docs)\n",
    "        self.save_bow() # bow is 'bag of words'\n",
    "        self.compute_word_document_frequency()\n",
    "        self.update_inverted_index_with_tf_idf_and_compute_document_norm()\n",
    "             \n",
    "    def compute_word_document_frequency(self):\n",
    "        for word in self.inverted_index.keys():\n",
    "            ### YOUR CODE HERE\n",
    "            self.word_document_frequency[word] = len(self.inverted_index[word].keys())\n",
    "            ### END YOUR CODE\n",
    "            \n",
    "    def update_inverted_index_with_tf_idf_and_compute_document_norm(self):\n",
    "        ### YOUR CODE HERE\n",
    "        N = len(self.document_term_frequency.keys()) # number of documents\n",
    "        for word in self.inverted_index.keys():\n",
    "            word_doc_weights = {}\n",
    "            for doc in self.inverted_index[word].keys():\n",
    "                tf = self.inverted_index[word][doc] / self.document_term_frequency[doc]\n",
    "                df = self.word_document_frequency[word]\n",
    "                tmp_arr = np.array([N / df])  # for numpy log10 function usage\n",
    "                idf = np.log10(tmp_arr)[0]\n",
    "                w_ij = tf * idf \n",
    "                word_doc_weights[doc] = w_ij  # replacing int with weight\n",
    "                if doc not in self.doc_norms.keys():\n",
    "                    self.doc_norms[doc] = w_ij ** 2\n",
    "                else:\n",
    "                    self.doc_norms[doc] += w_ij ** 2\n",
    "                    \n",
    "            self.inverted_index[word] = word_doc_weights\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        for doc in self.doc_norms.keys():\n",
    "            self.doc_norms[doc] = np.sqrt(self.doc_norms[doc]) \n",
    "            \n",
    "    def save_bow(self):\n",
    "        pd.DataFrame([self.inverted_index]).T.to_csv(self.bow_path)\n",
    "                \n",
    "tf_idf = TfIdf()\n",
    "tf_idf.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You need to run the TfIdf model without the DEBUG mode until this stage**\n",
    "\n",
    "## 1.11 Bag of words model:\n",
    "\n",
    "1. What is the computational complexity of this model, as a function of the number of docs in the corpus?\n",
    "2. How can we make this code better in terms running time (parallelization or other topics you find)? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR SOLUTION HERE\n",
    "1. Computational complexity of this model:\n",
    "    Words as V, Documents as D:\n",
    "    O(|V|*|D| + |D|) = O(|V|*|D|)\n",
    "\n",
    "2. Improving running time using parallelization:\n",
    "    In the current method we process each term in V one by one using a single processing unit. \n",
    "    since each term in V is unique, we can divide V into smaller batches and sent each bath to a seperate processing unit to run in parallel. \n",
    "    at the end, we combine all the dictionaries into one.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END YOUR SOLUTION HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 DocumentRetriever\n",
    "Not this retriever &#8595;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![dsafdsafsdafdsf](https://cdn3-www.dogtime.com/assets/uploads/2019/10/golden-cocker-retriever-mixed-dog-breed-pictures-cover-1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the following methods:\n",
    "\n",
    "`reduce_query_to_counts`: given a list of words returns a counter object with words as keys and counts as values.\n",
    "\n",
    "`rank`: given a query and relevant documents calculate the similarity (cosine or inner product simmialrity) between each document and the query.   \n",
    "Make sure to transform the query word counts to tf idf as well. \n",
    "\n",
    "`sort_and_retrieve_k_best`: returns the top k documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentRetriever:\n",
    "    def __init__(self, tf_idf):\n",
    "        self.sentence_preprocesser = preprocess_sentence  \n",
    "        self.vocab = set(tf_idf.unigram_count.keys())\n",
    "        self.n_docs = tf_idf.n_docs\n",
    "        self.inverted_index = tf_idf.inverted_index\n",
    "        self.word_document_frequency = tf_idf.word_document_frequency\n",
    "        self.doc_norms = tf_idf.doc_norms\n",
    "        \n",
    "    def rank(self,query : Dict[str,int],documents: Dict[str,Counter],metric: str ) -> Dict[int, float]:\n",
    "        result = {}  # key: DocID , value : float , similarity to query\n",
    "        query_len = np.sum(np.array(list(query.values())))\n",
    "        ### YOUR CODE HERE\n",
    "        # query tf-idf transformation  \n",
    "        # for each relevant doc: cosine similarity score\n",
    "        N = len(tf_idf.document_term_frequency.keys()) # number of documents\n",
    "        for term in query.keys():\n",
    "            tf_query = query[term] / query_len\n",
    "            idf_query = np.log10([N / self.word_document_frequency[term]])[0]\n",
    "            q = tf_query * idf_query\n",
    "\n",
    "            for doc in documents[term].keys():\n",
    "                if doc not in result:\n",
    "                    result[doc] = q * documents[term][doc]\n",
    "                else:\n",
    "                    result[doc] += q* documents[term][doc]\n",
    "        \n",
    "         ### END YOUR CODE\n",
    "\n",
    "        if metric == 'cosine':\n",
    "        ### YOUR CODE HERE\n",
    "            for doc in result.keys(): \n",
    "                # for each document, we use the result of the inner product as the numerator and the query_len as the denominator\n",
    "                # to produce the cosine metric rank\n",
    "                result[doc] *= self.doc_norms[doc] * (1 / query_len)\n",
    "        ### END YOUR CODE\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def sort_and_retrieve_k_best(self, scores: Dict[str, float],k :int):\n",
    "        ### YOUR CODE HERE \n",
    "        # rank similarity scores, return top k docs\n",
    "        return list(dict(Counter(scores).most_common(k)).keys())\n",
    "        ### END YOUR CODE\n",
    "        pass\n",
    "    \n",
    "    def reduce_query_to_counts(self, query : List)->  Counter:\n",
    "        ### YOUR CODE HERE\n",
    "        return Counter(query) # returning the Counter object  \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def get_top_k_documents(self,query : str, metric: str , k = 5) -> List[str]:\n",
    "        query = self.sentence_preprocesser(query)\n",
    "        query = [word for word in query if word in self.vocab] # filter nan \n",
    "        query_bow = self.reduce_query_to_counts(query)\n",
    "        relavant_documents = {word : self.inverted_index.get(word) for word in query}\n",
    "        ducuments_with_similarity = self.rank(query_bow,relavant_documents, metric)\n",
    "        return self.sort_and_retrieve_k_best(ducuments_with_similarity,k)\n",
    "        \n",
    "dr = DocumentRetriever(tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\maxpo\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\display.py:717: UserWarning: Consider using IPython.display.IFrame instead\n  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KT6ZtUbVw1M?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "query = \"Better stop dreaming of the quiet life, 'cause it's the one we'll never know And quit running for that runaway bus 'cause those rosy days are few And stop apologizing for the things you've never done 'Cause time is short and life is cruel but it's up to us to change This town called malice\"\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/KT6ZtUbVw1M?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[94798, 66192, 61393, 264880, 128160]\n",
      "[66192, 128160, 309297, 318295, 274541]\n"
     ]
    }
   ],
   "source": [
    "cosine_top_k = dr.get_top_k_documents(query, 'cosine')\n",
    "print(cosine_top_k)\n",
    "inner_product_top_k = dr.get_top_k_documents(query, 'inner_product')\n",
    "print(inner_product_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "##################################################\nsong #0 \nmore important is what i'm not doing. theirs less to\napologize for. non-action \n##################################################\n##################################################\nsong #1 \nI hear people talk\nI see people walk\nThey seem so out of touch\nI wanna get away so much\nAll the clockwork toys\nAre making too much noise\nIt's the machinery\nIt's breaking down, oh can't you see\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nThe picture doesn't change\nIt's just a frozen frame\nI wanna break the ice\nI wanna go to paradise\nThere is nowhere to hide\nI'll take you for a ride\nBut not if you kiss and tell\nI don't mean on a carousel\nWon't you run runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nOne day I'm to say my\nThree wishes came true\nTill then I pretend I'm\nEscaping with you, you, you, you\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me\nRun runaway, run runaway\nRun runaway with me \n##################################################\n##################################################\nsong #2 \nStop\nStop\nStop\nMake it stop \n##################################################\n##################################################\nsong #3 \nBe more quiet, now, and wait for a voice to say 'be more quiet.. \n##################################################\n##################################################\nsong #4 \nI always wanted you by my side\nI felt you we're my guide\nThe one who showed me what's right\nI used to think that you we're my light\nAnd trusted in your smile\nBut now you have decide\nRunaway, runaway, runaway\nSearching everyday, try to find your way\nRunaway, runaway, runaway\nWanna find you, oh baby wanna\nRunaway, runaway, runaway\nEverything is grey, miss you more each day\nRunaway, runaway, runaway\nI will find you, you'll never runaway\nI always wanted you by my side\nI felt you we're my guide\nThe one who show me what's right\nI used to think that you we're my light\nAnd trusted in your smile\nBut now you have decide\nRunaway, runaway, runaway\nSearching everyday, try to find your way\nRunaway, runaway, runaway\nWanna find you, oh baby wanna\nRunaway, runaway, runaway\nEverything is grey, miss you more each day\nRunaway, runaway, runaway\nI will find you, you'll never runaway\nI'm running now, I'm running away\nSearching for, searching for your smile\nEvery hour I'm looking for you\nI'm looking for away, I'm looking for you\nRunaway, runaway, runaway\nSearching everyday, try to find your way\nRunaway, runaway, runaway\nWanna find you, oh baby wanna\nRunawaaaaay\n(Searching everyday, try to find your way)\nOh baby, baby ... runawaaay\nSearch \n##################################################\n"
     ]
    }
   ],
   "source": [
    "for index, song in enumerate(pd.read_csv(INPUT_FILE_PATH,usecols = [5]).iloc[cosine_top_k]['lyrics']):\n",
    "    sep = \"#\"*50\n",
    "    print(F\"{sep}\\nsong #{index} \\n{song} \\n{sep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 term statistics:\n",
    "Use \"tf_idf\" object that we created earlier and answer the following questions:\n",
    "\n",
    "1. How many unique words we have?\n",
    "2. How many potential word bigrams we have (depend on the unique words we have)? How many actual word bigrams we have? How do you explain this difference?\n",
    "3. What is the storage size of the input file \"lyrics.csv\"? What is the output file (bow.csv) size? how do you explain this difference?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1. There are 387734 unique words.\n2. Potentially, there are (387734 choose 2) = 75018268185 unique bigrams while 6310554 were found.\n3. 324.632382 (MB), 193.272012 (MB) are the storage sizes of lyrics.csv and bow.csv files respectively.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\n### Your verbal solution here\\n\\n\\n\\n\\n### End your verbal solution here\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# 1. \n",
    "### YOUR SOLUTION HERE\n",
    "n_unigr = len(tf_idf.unigram_count.keys())\n",
    "print(f\"1. There are {n_unigr} unique words.\")\n",
    "### END YOUR SOLUTION\n",
    "\n",
    "\"\"\"\n",
    "### Your verbal solution here\n",
    "There are 387346 unique words.\n",
    "### End your verbal solution here\n",
    "\"\"\"\n",
    "\n",
    "# 2.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "n_bigr = len(tf_idf.bigram_count.keys())\n",
    "print(f\"2. Potentially, there are ({n_unigr} choose 2) = {75018268185} unique bigrams while {n_bigr} were found.\")\n",
    "### END YOUR SOLUTION\n",
    "\n",
    "\"\"\"\n",
    "### Your verbal solution here\n",
    "Potentially, there are (n_unigr choose 2) unique bigrams, because we are choosing all possible pairs out of our corpus.\n",
    "While in practice only {n_bigr} were found.\n",
    "### End your verbal solution here\n",
    "\"\"\"\n",
    "\n",
    "# 3.\n",
    "### YOUR SOLUTION HERE\n",
    "print(f\"3. {INPUT_FILE_PATH.stat().st_size*1e-6} (MB), {BOW_PATH.stat().st_size*1e-6} (MB) are the storage sizes of lyrics.csv and bow.csv files respectively.\")\n",
    "### END YOUR SOLUTION\n",
    "\n",
    "\"\"\"\n",
    "### Your verbal solution here\n",
    "the storage size of the lyrics.csv file is 324.6 (MB) and the storage size of bow.csv is 193.3 (MB\n",
    "As expected, the BOW file storage size is smaller than the lyrics file as a result of the preprocessing which was applied, like removing stop words and stemming.\n",
    "\n",
    "### End your verbal solution here\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 NgramSpellingCorrector\n",
    "Now we will implement a Ngarm (character Ngrams) spelling corrector. That is, we have an out of vocabulary word (v) and we want to retrieve the most similar words (in our vocabulary) to this word.\n",
    "we will model the similarity of two words by-\n",
    "\n",
    "$$sim(v,w) := prior \\cdot likelihood = p(w) \\cdot P(v|w) $$ \n",
    "$$P(v|w) := JaccardIndex =  \\frac{|X \\cap Y|}{|X \\cup Y|}$$\n",
    "\n",
    "Where v is an out of vocabulary word (typo or spelling mistake), w is in a vocabulary word, X is the ngram set of v and Y is the ngram set of w.\n",
    "For example, if n == 3, the set of ngrams for word \"banana\" is set(\"ban\",\"ana\",\"nan\",\"ana\") = {\"ban\",\"ana\",\"nan\"}\n",
    "\n",
    "In order to do it efficently, we will first construct an index from the possible Ngrams we have seen in our corpus to the words that those Ngrams appear in, in order prevent comparing v to all of the words in our corpus.\n",
    "Then, we will implement a function that computes this similarity.\n",
    "\n",
    "* Make sure you compute the JaccardIndex efficently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' \\nfor example - get_bigrams is a generator, which is an object we can loop on:\\nfor ngram in get_bigrams(word):\\n    DO SOMETHING\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "def get_bigrams(word):\n",
    "    for ngram in nltk.ngrams(word, 2):\n",
    "        yield \"\".join(list(ngram))\n",
    "    \n",
    "def get_trigrams(word):\n",
    "    for ngram in nltk.ngrams(word, 3):\n",
    "        yield \"\".join(list(ngram))\n",
    "        \n",
    "\"\"\" \n",
    "for example - get_bigrams is a generator, which is an object we can loop on:\n",
    "for ngram in get_bigrams(word):\n",
    "    DO SOMETHING\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NgramSpellingCorrector:\n",
    "    def __init__(self, unigram_counts: Counter, get_n_gram: callable):\n",
    "        self.unigram_counts = unigram_counts\n",
    "        self.ngram_index = {}\n",
    "        self.get_n_grams = get_n_gram\n",
    "    \n",
    "    def build_index(self) -> None:\n",
    "        ### YOUR CODE HERE\n",
    "        # for each word that was collected during docs indexing (fit process):\n",
    "        for word in self.unigram_counts.keys():\n",
    "            # using word as key refering to list of ngrams values:\n",
    "            self.ngram_index[word] = list(self.get_n_grams(word))  \n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def get_top_k_words(self,word:str,k=5) -> List[str]:\n",
    "        ### YOUR CODE HERE\n",
    "        word_ngram = list(self.get_n_grams(word))  # getting word's n_grams values\n",
    "        sim_scores = {}  # to keep resemblance score for each term\n",
    "        for term in self.unigram_counts.keys():  # for each term in the corpus\n",
    "            prior = self.unigram_counts[term]  # dividing with (# total terms) is redundant for comparison process\n",
    "            x_inter_y = list(set(word_ngram) & set(self.ngram_index[term]))  # getting intersection for JI numerator\n",
    "            temp = word_ngram[:]\n",
    "            temp.extend(self.ngram_index[term])\n",
    "            x_unif_y = set(temp)  # denominator for JI\n",
    "            ji = len(x_inter_y) / len(x_unif_y)  # calculating Jacard Index\n",
    "            sim_scores[term] = prior * ji  # calculating and storing term's similarity to input word\n",
    "        return list(dict(Counter(sim_scores).most_common(k)).keys())  # returning list of top k candidate terms\n",
    "        ### END YOUR CODE\n",
    "\n",
    "class BigramSpellingCorrector(NgramSpellingCorrector):\n",
    "    def __init__(self, unigram_counts: Counter):\n",
    "        super().__init__(unigram_counts, get_bigrams)\n",
    "        \n",
    "        \n",
    "class TrigramSpellingCorrector(NgramSpellingCorrector):\n",
    "    def __init__(self, unigram_counts: Counter):\n",
    "        super().__init__(unigram_counts, get_trigrams)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUR TESTING:\n",
    "# D ={\"one\" : 2, \"two\" : 3, \"three\" : 4, 'plane': 66666, 'fish': 10, 'dog': 1000000, 'plant': 4555, 'plan': 1}\n",
    "\n",
    "# out_of_vocab_word = 'plan'\n",
    "# trigram_spelling_corrector = TrigramSpellingCorrector(D)\n",
    "# trigram_spelling_corrector.build_index()\n",
    "# trigram_spelling_corrector.get_top_k_words(out_of_vocab_word, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['like', 'caus', 'life', 'still', 'time']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "out_of_vocab_word = 'supercalifragilisticexpialidocious'\n",
    "bigram_spelling_corrector = BigramSpellingCorrector(tf_idf.unigram_count)\n",
    "bigram_spelling_corrector.build_index()\n",
    "bigram_spelling_corrector.get_top_k_words(out_of_vocab_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['life', 'still', 'call', 'listen', 'hous']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "trigram_spelling_corrector = TrigramSpellingCorrector(tf_idf.unigram_count)\n",
    "trigram_spelling_corrector.build_index()\n",
    "trigram_spelling_corrector.get_top_k_words(out_of_vocab_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Language model\n",
    "Calculate the log likelihood of a sentence. Once with a bigram markovian langauge model, and once with a trigram model.\n",
    "for example - the likelihood of the senetence \"spiderman spiderman does whatever a spider can\" for the bigram model is: \n",
    "$$p(spiderman)\\cdot p(spiderman|spiderman) \\cdot  p(does|spiderman) \\cdot p(whatever|does) \\cdot  p(a|whatever) \\cdot  p(spider|a) \\cdot p(can|spider)$$\n",
    "\n",
    "And for the trigram model:\n",
    "$$p(spiderman,spiderman)\\cdot p(does|spiderman,spiderman) \\cdot  p(whatever|spiderman,does) \\cdot p(a|does,whatever) \\cdot  p(spider|whatever,a) \\cdot  p(can|a, spider)$$\n",
    "\n",
    "Since we do not want a zero probability sentence use Laplace smoothing, as you have seen in the lecture, or here https://en.wikipedia.org/wiki/Additive_smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bigram log likelihood is 0.0006420015518082552\nTrigram log likelihood is 0.00032191705393113106\n"
     ]
    }
   ],
   "source": [
    "# for the probability smoothing\n",
    "NUMERATOR_SMOOTHING = 1 # alpha in https://en.wikipedia.org/wiki/Additive_smoothing\n",
    "DENOMINATOR_SMOOTHING = 10**4 # d in https://en.wikipedia.org/wiki/Additive_smoothing\n",
    "def sentence_log_probabilty(unigrams : Counter, bigrams  : Counter,trigrams : Counter, sentence: str):\n",
    "    bigram_log_likelilhood, trigram_log_likelilhood = 0, 0\n",
    "    words_in_sentence = sentence.split()\n",
    "    n_words = len(words_in_sentence)\n",
    "    for i, word in enumerate(words_in_sentence):\n",
    "        ### YOUR CODE HERE\n",
    "        if i == 0: # starting by calculating the prior probability \n",
    "            bigram_log_likelilhood += np.log(unigrams[word] + NUMERATOR_SMOOTHING)/ (len(unigrams.keys()) +DENOMINATOR_SMOOTHING)\n",
    "            \n",
    "            ### MAXIM AND DANIEL TEST FOR PRIOR FOR TRIGRAMS\n",
    "            trigram_log_likelilhood += np.log(bigrams[(word,words_in_sentence[i+1])] + NUMERATOR_SMOOTHING) / (len(bigrams.keys()) + DENOMINATOR_SMOOTHING)\n",
    "            ### MAXIM AND DANIEL TEST FOR PRIOR FOR TRIGRAMS\n",
    "\n",
    "\n",
    "        # calculating the conditional probability\n",
    "        if i < n_words - 1:\n",
    "            N1 = unigrams[word]\n",
    "            bigram_log_likelilhood += np.log(bigrams[(word,words_in_sentence[i+1])] + NUMERATOR_SMOOTHING) / (N1 + DENOMINATOR_SMOOTHING)\n",
    "            \n",
    "            #trigram_log_likelilhood += np.log(bigrams[(word,words_in_sentence[i+1])] + NUMERATOR_SMOOTHING) / (N1 + DENOMINATOR_SMOOTHING)\n",
    "\n",
    "            #MAXIM AND DANIEL TEST FOR PRIOR FOR TRIGRAMS\n",
    "              \n",
    "        if i < n_words - 2:\n",
    "            N2 = bigrams[word, words_in_sentence[i+1]]\n",
    "            trigram_log_likelilhood += np.log(trigrams[word,words_in_sentence[i+1],words_in_sentence[i+2]] + NUMERATOR_SMOOTHING) /  (N2 + DENOMINATOR_SMOOTHING)\n",
    "        \n",
    "    \n",
    "#        bigram_log_likelilhood = np.e**(bigram_log_likelilhood)\n",
    "#        trigram_log_likelilhood = np.e**(trigram_log_likelilhood)\n",
    "#         bigram_log_likelilhood = np.log(bigram_log_likelilhood)\n",
    "#         trigram_log_likelilhood = np.log(trigram_log_likelilhood)\n",
    "        \n",
    "        ### END YOUR CODE\n",
    "    return (bigram_log_likelilhood,trigram_log_likelilhood)\n",
    "   \n",
    "sentence = \"spider man spider man does whatever a spider can\"\n",
    "bigram_log_likelilhood, trigram_log_likelilhood = sentence_log_probabilty(tf_idf.unigram_count, tf_idf.bigram_count, tf_idf.trigram_count, sentence)\n",
    "print(F\"Bigram log likelihood is {bigram_log_likelilhood}\")\n",
    "print(F\"Trigram log likelihood is {trigram_log_likelilhood}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.51 Language model: B\n",
    "For each model what is the next word prediciton for the sentnence \"like big\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bigram model next word prediction: ('big', 704)\n",
      "Trigram model next word prediction: ('deal', 41)\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "bigram_potential_next_words = [(k[1], tf_idf.bigram_count[k]) for k in tf_idf.bigram_count.keys() if k[0]=='big']\n",
    "best_candidate_bi = ('', 0)\n",
    "for word, cntr in bigram_potential_next_words:\n",
    "    if cntr > best_candidate_bi[1]:\n",
    "        best_candidate_bi = (word, cntr)\n",
    "print(f\"Bigram model next word prediction: {best_candidate_bi}\")\n",
    "\n",
    "trigram_potential_next_words = [(k[2], tf_idf.trigram_count[k]) for k in tf_idf.trigram_count.keys() if k[0]=='like' and  k[1]=='big']\n",
    "best_candidate_tri = ('', 0)\n",
    "for word, cntr in trigram_potential_next_words:\n",
    "    if cntr > best_candidate_tri[1]:\n",
    "        best_candidate_tri = (word, cntr)\n",
    "print(f\"Trigram model next word prediction: {best_candidate_tri}\")\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "stemmer.stem('running')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "'a' in stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'pecialcharactersspaces'"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "string = \"Special $#! characters   spaces 888323\"\n",
    "''.join(e for e in string if e in allowed_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.5228787452803374"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "N = 1e6\n",
    "\n",
    "df = 300\n",
    "tmp_arr = np.array([N/df])\n",
    "\n",
    "idf = np.log10(tmp_arr)\n",
    "idf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 1038: 0.004561948618469171,\n",
       " 1040: 0.0034137030478340736,\n",
       " 1046: 0.004014514784252871,\n",
       " 1047: 0.0035843882002257773,\n",
       " 1048: 0.017669519296887638,\n",
       " 1055: 0.006272679350395111,\n",
       " 1057: 0.002900660971280976,\n",
       " 1068: 0.024934874436353234,\n",
       " 1072: 0.012019505342074464,\n",
       " 1073: 0.007720220738947829,\n",
       " 1083: 0.039917050411605245,\n",
       " 1084: 0.007750028541028708,\n",
       " 1086: 0.025734069129826093,\n",
       " 1089: 0.004825137961842393,\n",
       " 1094: 0.001613550958300993,\n",
       " 1095: 0.01024110914350222,\n",
       " 1101: 0.004014514784252871,\n",
       " 1108: 0.010325398107646273,\n",
       " 1115: 0.01645292944365931,\n",
       " 1116: 0.009157196131963665,\n",
       " 1211: 0.012390477729175526,\n",
       " 1248: 0.015930614223225677,\n",
       " 1279: 0.027125099893600478,\n",
       " 1308: 0.0020908931167983704,\n",
       " 1320: 0.029272503635177183,\n",
       " 1321: 0.004079791447411454,\n",
       " 1325: 0.00487198396147193,\n",
       " 1327: 0.002819181730514656,\n",
       " 1329: 0.00880376049178261,\n",
       " 1331: 0.0059036982121365746,\n",
       " 1349: 0.017010655865478265,\n",
       " 1355: 0.0029518491060682873,\n",
       " 1358: 0.00512055457175111,\n",
       " 1360: 0.03386477195305336,\n",
       " 1364: 0.007720220738947829,\n",
       " 1365: 0.00583505055850708,\n",
       " 1366: 0.003662878452785466,\n",
       " 1368: 0.00506883179829908,\n",
       " 1369: 0.005575714978128987,\n",
       " 1374: 0.008505327932739132,\n",
       " 1379: 0.00974396792294386,\n",
       " 1380: 0.027572216924813674,\n",
       " 1385: 0.010103644591240446,\n",
       " 1386: 0.004113232360914827,\n",
       " 1387: 0.002509071740158044,\n",
       " 1388: 0.005282256295069567,\n",
       " 1389: 0.006475023845569147,\n",
       " 1394: 0.004289011521637683,\n",
       " 1399: 0.015206495394897239,\n",
       " 1400: 0.007379622765170718,\n",
       " 1402: 0.006602820368836958,\n",
       " 1403: 0.00604595600038083,\n",
       " 1404: 0.012390477729175526,\n",
       " 1405: 0.005395853204640956,\n",
       " 1406: 0.006119687171117182,\n",
       " 1408: 0.006874169151117929,\n",
       " 1411: 0.007067807718755054,\n",
       " 1413: 0.007661287756207768,\n",
       " 1415: 0.005338450510974562,\n",
       " 1427: 0.004325985758893179,\n",
       " 1429: 0.005702435773086464,\n",
       " 1430: 0.03744883194265737,\n",
       " 1432: 0.011404871546172929,\n",
       " 1433: 0.013205640737673916,\n",
       " 1436: 0.040145147842528706,\n",
       " 1437: 0.009123897236938343,\n",
       " 1438: 0.03136339675197555,\n",
       " 1439: 0.006690857973754785,\n",
       " 1474: 0.027125099893600478,\n",
       " 1480: 0.010676901021949124,\n",
       " 1482: 0.00604595600038083,\n",
       " 1483: 0.007168776400451555,\n",
       " 1484: 0.01209191200076166,\n",
       " 1485: 0.00487198396147193,\n",
       " 1486: 0.020072573921264353,\n",
       " 1487: 0.0065170694549559595,\n",
       " 1490: 0.014615951884415793,\n",
       " 1491: 0.017303943035572717,\n",
       " 1493: 0.004401880245891305,\n",
       " 1494: 0.006690857973754785,\n",
       " 1497: 0.015520031382420892,\n",
       " 1498: 0.012043544352758612,\n",
       " 1502: 0.0034370845755589646,\n",
       " 1503: 0.012545358700790222,\n",
       " 1508: 0.045619486184691714,\n",
       " 1509: 0.015520031382420892,\n",
       " 1534: 0.017921941001128885,\n",
       " 1552: 0.0029869901668548144,\n",
       " 1553: 0.011535962023715146,\n",
       " 1554: 0.005767981011857573,\n",
       " 1564: 0.004779184266967704,\n",
       " 1565: 0.016727144934386963,\n",
       " 1569: 0.007720220738947829,\n",
       " 1570: 0.01024110914350222,\n",
       " 1582: 0.006488978638339769,\n",
       " 1585: 0.006488978638339769,\n",
       " 1587: 0.009613301686429288,\n",
       " 1588: 0.0008651971517786359,\n",
       " 1589: 0.001005639976015248,\n",
       " 1590: 0.001482464839088948,\n",
       " 1593: 0.01576380150884635,\n",
       " 1594: 0.0017424109306653085,\n",
       " 1601: 0.02805173374089739,\n",
       " 1607: 0.005767981011857573,\n",
       " 1610: 0.03501030335104248,\n",
       " 1611: 0.005200148684265377,\n",
       " 1614: 0.005926941118483569,\n",
       " 1615: 0.0031072095853350397,\n",
       " 1616: 0.0034607886071145438,\n",
       " 1618: 0.002484229445701034,\n",
       " 1644: 0.004401880245891305,\n",
       " 1645: 0.0027572216924813676,\n",
       " 1646: 0.005670218621826088,\n",
       " 1656: 0.01090900756590454,\n",
       " 1658: 0.0033906374867000598,\n",
       " 1662: 0.029518491060682873,\n",
       " 1664: 0.014135615437510109,\n",
       " 1670: 0.004046889903480716,\n",
       " 1672: 0.003196269732685407,\n",
       " 1675: 0.002900660971280976,\n",
       " 1678: 0.013562549946800239,\n",
       " 1681: 0.010036286960632176,\n",
       " 1682: 0.0033232738280238997,\n",
       " 1683: 0.002742154907276551,\n",
       " 1686: 0.020072573921264353,\n",
       " 1687: 0.004689853719921578,\n",
       " 1689: 0.007067807718755054,\n",
       " 1691: 0.006119687171117182,\n",
       " 1697: 0.007489766388531475,\n",
       " 1700: 0.00604595600038083,\n",
       " 1704: 0.00875257583776062,\n",
       " 1705: 0.015681698375987776,\n",
       " 1706: 0.003059843585558591,\n",
       " 1717: 0.004363603026361816,\n",
       " 1731: 0.0035716323703317353,\n",
       " 1737: 0.005606864223816859,\n",
       " 1739: 0.0036363358553015133,\n",
       " 1743: 0.006602820368836958,\n",
       " 1752: 0.007272671710603027,\n",
       " 1758: 0.007780067411342773,\n",
       " 1789: 0.007489766388531475,\n",
       " 1820: 0.006874169151117929,\n",
       " 1821: 0.011404871546172929,\n",
       " 1822: 0.009379707439843156,\n",
       " 1827: 0.00512055457175111,\n",
       " 1830: 0.01858571659376329,\n",
       " 1860: 0.01024110914350222,\n",
       " 1868: 0.02230285991251595,\n",
       " 1872: 0.005702435773086464,\n",
       " 1881: 0.005338450510974562,\n",
       " 1890: 0.0034607886071145438,\n",
       " 1966: 0.004147226016790156,\n",
       " 1974: 0.01433755280090311,\n",
       " 1979: 0.008960970500564443,\n",
       " 1980: 0.012545358700790222,\n",
       " 1986: 0.012239374342234363,\n",
       " 1989: 0.006690857973754785,\n",
       " 1994: 0.024478748684468726,\n",
       " 2001: 0.028839905059287865,\n",
       " 2004: 0.020072573921264353,\n",
       " 2006: 0.007325756905570932,\n",
       " 2007: 0.00487198396147193,\n",
       " 2010: 0.016187559613922865,\n",
       " 2012: 0.026411281475347832,\n",
       " 2013: 0.010676901021949124,\n",
       " 2015: 0.020072573921264353,\n",
       " 2016: 0.006272679350395111,\n",
       " 2017: 0.004363603026361816,\n",
       " 2018: 0.004113232360914827,\n",
       " 2020: 0.006119687171117182,\n",
       " 2021: 0.00757455619670353,\n",
       " 2024: 0.0065170694549559595,\n",
       " 2026: 0.03028190031225226,\n",
       " 2028: 0.00583505055850708,\n",
       " 2029: 0.014759245530341436,\n",
       " 2030: 0.004181786233596741,\n",
       " 2032: 0.011404871546172929,\n",
       " 2033: 0.004147226016790156,\n",
       " 2036: 0.0026834991873348063,\n",
       " 2039: 0.002023444951740358,\n",
       " 2043: 0.004480485250282221,\n",
       " 2047: 0.002851217886543232,\n",
       " 2052: 0.004325985758893179,\n",
       " 2053: 0.009292858296881645,\n",
       " 2080: 0.010676901021949124,\n",
       " 2084: 0.026411281475347832,\n",
       " 2090: 0.00604595600038083,\n",
       " 2091: 0.004779184266967704,\n",
       " 2103: 0.010346687588280595,\n",
       " 2104: 0.023895921334838515,\n",
       " 2105: 0.003022978000190415,\n",
       " 2106: 0.0052272327919959255,\n",
       " 2111: 0.025955914553359077,\n",
       " 2112: 0.012704160709660984,\n",
       " 2115: 0.004968458891402068,\n",
       " 2118: 0.0028034321119084294,\n",
       " 2125: 0.003509191244976286,\n",
       " 2127: 0.0066465476560477995,\n",
       " 2128: 0.030229780001904148,\n",
       " 2134: 0.0059036982121365746,\n",
       " 2135: 0.010036286960632176,\n",
       " 2152: 0.036242147357838414,\n",
       " 2153: 0.0047340976229397055,\n",
       " 2196: 0.050816642838643934,\n",
       " 2198: 0.009839497020227624,\n",
       " 2199: 0.005338450510974562,\n",
       " 2200: 0.028139122319529468,\n",
       " 2201: 0.00971253576835372,\n",
       " 2203: 0.0037171433187526584,\n",
       " 2211: 0.011491931634311652,\n",
       " 2212: 0.0059036982121365746,\n",
       " 2217: 0.07806000969380582,\n",
       " 2218: 0.0038900337056713865,\n",
       " 2219: 0.005514443384962735,\n",
       " 2224: 0.009528120532245738,\n",
       " 2225: 0.007902588157978093,\n",
       " 2228: 0.00512055457175111,\n",
       " 2231: 0.0047340976229397055,\n",
       " 2233: 0.004919748510113812,\n",
       " 2238: 0.007965307111612838,\n",
       " 2243: 0.01858571659376329,\n",
       " 2245: 0.007902588157978093,\n",
       " 2251: 0.009041699964533493,\n",
       " 2253: 0.007489766388531475,\n",
       " 2257: 0.0052272327919959255,\n",
       " 2258: 0.008433854588766535,\n",
       " 2259: 0.009839497020227624,\n",
       " 2261: 0.01024110914350222,\n",
       " 2264: 0.004603801358088155,\n",
       " 2265: 0.0052272327919959255,\n",
       " 2272: 0.0026551023705376126,\n",
       " 2275: 0.015206495394897239,\n",
       " 2276: 0.0033678815304134823,\n",
       " 2280: 0.01967899404045525,\n",
       " 2285: 0.005638363461029312,\n",
       " 2290: 0.014069561159764734,\n",
       " 2291: 0.018083399929066987,\n",
       " 2292: 0.004520849982266747,\n",
       " 2296: 0.00458277943407862,\n",
       " 2298: 0.00968130574980596,\n",
       " 2299: 0.0017921941001128887,\n",
       " 2301: 0.0033454289868773924,\n",
       " 2302: 0.001015818518282609,\n",
       " 2305: 0.003830643878103884,\n",
       " 2306: 0.0022604249911333733,\n",
       " 2307: 0.017763339753331286,\n",
       " 2310: 0.0017794835036581873,\n",
       " 2311: 0.0016345744235557293,\n",
       " 2312: 0.003176040177415246,\n",
       " 2313: 0.001158924591297018,\n",
       " 2315: 0.0017424109306653085,\n",
       " 2316: 0.00201531866679361,\n",
       " 2317: 0.0026136163959979627,\n",
       " 2320: 0.001158924591297018,\n",
       " 2321: 0.007517817948039084,\n",
       " 2322: 0.0017068515239170368,\n",
       " 2323: 0.001960212296998472,\n",
       " 2324: 0.007018382489952572,\n",
       " 2326: 0.001937507135257177,\n",
       " 2328: 0.0016292673637389899,\n",
       " 2329: 0.0019913267779032096,\n",
       " 2330: 0.001588020088707623,\n",
       " 2331: 0.003905170023592287,\n",
       " 2333: 0.00500562940679909,\n",
       " 2335: 0.0031363396751975556,\n",
       " 2338: 0.004113232360914827,\n",
       " 2339: 0.0033566177125860124,\n",
       " 2340: 0.004575814723692482,\n",
       " 2341: 0.002521680140862356,\n",
       " 2342: 0.05018143480316089,\n",
       " 2343: 0.001754595622488143,\n",
       " 2344: 0.0038160786922555806,\n",
       " 2346: 0.008093779806961432,\n",
       " 2348: 0.02181801513180908,\n",
       " 2350: 0.005514443384962735,\n",
       " 2353: 0.0017731955760834236,\n",
       " 2355: 0.0029518491060682873,\n",
       " 2359: 0.0022604249911333733,\n",
       " 2365: 0.004313590384225864,\n",
       " 2368: 0.006969643722661234,\n",
       " 2371: 0.004749031684841724,\n",
       " 2374: 0.00215370964820433,\n",
       " 2377: 0.00880376049178261,\n",
       " 2405: 0.0034370845755589646,\n",
       " 2407: 0.005018143480316088,\n",
       " 2409: 0.00974396792294386,\n",
       " 2416: 0.060621867547442684,\n",
       " 2429: 0.007840849187993888,\n",
       " 2432: 0.0066465476560477995,\n",
       " 2438: 0.003951294078989046,\n",
       " 2443: 0.003022978000190415,\n",
       " 2444: 0.0432598575889318,\n",
       " 2446: 0.003951294078989046,\n",
       " 2448: 0.0038900337056713865,\n",
       " 2463: 0.010676901021949124,\n",
       " 2465: 0.027878574890644936,\n",
       " 2466: 0.022469299165594425,\n",
       " 2481: 0.008505327932739132,\n",
       " 2484: 0.011404871546172929,\n",
       " 2485: 0.005338450510974562,\n",
       " 2496: 0.006119687171117182,\n",
       " 2497: 0.015440441477895658,\n",
       " 2498: 0.09694140814246989,\n",
       " 2499: 0.03717143318752658,\n",
       " 2500: 0.017010655865478265,\n",
       " 2508: 0.007603247697448619,\n",
       " 2590: 0.00604595600038083,\n",
       " 2596: 0.02205777353985094,\n",
       " 2597: 0.017156046086550733,\n",
       " 2598: 0.028139122319529468,\n",
       " 2631: 0.015681698375987776,\n",
       " 2654: 0.007489766388531475,\n",
       " 2658: 0.008881669876665643,\n",
       " 2659: 0.006602820368836958,\n",
       " 2661: 0.02418382400152332,\n",
       " 2663: 0.0025472809544751715,\n",
       " 2695: 0.020072573921264353,\n",
       " 2697: 0.002126331983184783,\n",
       " 2702: 0.022809743092345857,\n",
       " 2713: 0.011151429956257975,\n",
       " 2730: 0.00512055457175111,\n",
       " 2738: 0.034607886071145434,\n",
       " 2751: 0.014135615437510109,\n",
       " 2799: 0.003982653555806419,\n",
       " 2803: 0.001960212296998472,\n",
       " 2805: 0.009258567306856251,\n",
       " 2806: 0.0016452929443659307,\n",
       " 2807: 0.001915321939051942,\n",
       " 2808: 0.0030412990789794475,\n",
       " 2809: 0.0021629928794465896,\n",
       " 2810: 0.0017303943035572719,\n",
       " 2811: 0.05822155419151263,\n",
       " 2812: 0.008181755674428404,\n",
       " 2814: 0.0037448831942657377,\n",
       " 2815: 0.013939287445322468,\n",
       " 2816: 0.012961994229598752,\n",
       " 2819: 0.016938880946214645,\n",
       " 2820: 0.002126331983184783,\n",
       " 2822: 0.0016783088562930062,\n",
       " 2824: 0.0049439837244493485,\n",
       " 2826: 0.015406580860619568,\n",
       " 2828: 0.004507314503277924,\n",
       " 2829: 0.002521680140862356,\n",
       " 2831: 0.002509071740158044,\n",
       " 2832: 0.0023019006790440774,\n",
       " 2833: 0.004046889903480716,\n",
       " 2835: 0.004603801358088155,\n",
       " 2836: 0.001915321939051942,\n",
       " 2838: 0.002851217886543232,\n",
       " 2840: 0.002772454961500601,\n",
       " 2841: 0.005043360281724712,\n",
       " 2842: 0.007434286637505317,\n",
       " 2843: 0.0022809743092345857,\n",
       " 2844: 0.004646429148440823,\n",
       " 2846: 0.0016083793206141308,\n",
       " 2847: 0.0022204174691664107,\n",
       " 2848: 0.009839497020227624,\n",
       " 2850: 0.0047118718125033696,\n",
       " 2853: 0.0017244479313800992,\n",
       " 2859: 0.015440441477895658,\n",
       " 2861: 0.007965307111612838,\n",
       " 2863: 0.004480485250282221,\n",
       " 2867: 0.03136339675197555,\n",
       " 2868: 0.017303943035572717,\n",
       " 2870: 0.014759245530341436,\n",
       " 2871: 0.027125099893600478,\n",
       " 2872: 0.021353802043898248,\n",
       " 2873: 0.011404871546172929,\n",
       " 2917: 0.008505327932739132,\n",
       " 2931: 0.005702435773086464,\n",
       " 2939: 0.007168776400451555,\n",
       " 2941: 0.0047340976229397055,\n",
       " 2942: 0.0052272327919959255,\n",
       " 2955: 0.006352080354830492,\n",
       " 2956: 0.012624260327839218,\n",
       " 2961: 0.01090900756590454,\n",
       " 2962: 0.0066465476560477995,\n",
       " 2968: 0.0038900337056713865,\n",
       " 2973: 0.012390477729175526,\n",
       " 2980: 0.018818038051185332,\n",
       " 2982: 0.00604595600038083,\n",
       " 2983: 0.00487198396147193,\n",
       " 2984: 0.010103644591240446,\n",
       " 2985: 0.006119687171117182,\n",
       " 2988: 0.006272679350395111,\n",
       " 3001: 0.01090900756590454,\n",
       " 3004: 0.012239374342234363,\n",
       " 3006: 0.09558368533935406,\n",
       " 3007: 0.007780067411342773,\n",
       " 3009: 0.00880376049178261,\n",
       " 3011: 0.007720220738947829,\n",
       " 3013: 0.003920424593996944,\n",
       " 3015: 0.009936917782804136,\n",
       " 3017: 0.006272679350395111,\n",
       " 3022: 0.002389592133483852,\n",
       " 3030: 0.013562549946800239,\n",
       " 3041: 0.007965307111612838,\n",
       " 3043: 0.006119687171117182,\n",
       " 3046: 0.011046227786859314,\n",
       " 3051: 0.01013766359659816,\n",
       " 3052: 0.0034607886071145438,\n",
       " 3057: 0.005638363461029312,\n",
       " 3058: 0.00604595600038083,\n",
       " 3059: 0.009292858296881645,\n",
       " 3062: 0.015440441477895658,\n",
       " 3066: 0.007603247697448619,\n",
       " 3070: 0.01102888676992547,\n",
       " 3071: 0.004561948618469171,\n",
       " 3073: 0.0033906374867000598,\n",
       " 3074: 0.005514443384962735,\n",
       " 3075: 0.026411281475347832,\n",
       " 3076: 0.004363603026361816,\n",
       " 3079: 0.003496964097781246,\n",
       " 3084: 0.017454412105447265,\n",
       " 3085: 0.007379622765170718,\n",
       " 3090: 0.0066465476560477995,\n",
       " 3096: 0.010454465583991851,\n",
       " 3097: 0.00512055457175111,\n",
       " 3098: 0.010988635358356398,\n",
       " 3099: 0.02042267695477478,\n",
       " 3100: 0.002424223903534342,\n",
       " 3101: 0.009041699964533493,\n",
       " 3103: 0.0031560650819598044,\n",
       " 3104: 0.003004876335518616,\n",
       " 3105: 0.02664500962999693,\n",
       " 3108: 0.007168776400451555,\n",
       " 3109: 0.005767981011857573,\n",
       " 3112: 0.012867034564913046,\n",
       " 3114: 0.02069337517656119,\n",
       " 3115: 0.017303943035572717,\n",
       " 3127: 0.013205640737673916,\n",
       " 3146: 0.018247794473876686,\n",
       " 3153: 0.014759245530341436,\n",
       " 3158: 0.007780067411342773,\n",
       " 3159: 0.004216927294383267,\n",
       " 3160: 0.009379707439843156,\n",
       " 3161: 0.00506883179829908,\n",
       " 3163: 0.005767981011857573,\n",
       " 3166: 0.013322504814998465,\n",
       " 3173: 0.038601103694739146,\n",
       " 3196: 0.005282256295069567,\n",
       " 3204: 0.014759245530341436,\n",
       " 3215: 0.004401880245891305,\n",
       " 3216: 0.007720220738947829,\n",
       " 3219: 0.021506329201354667,\n",
       " 3224: 0.009123897236938343,\n",
       " 3229: 0.0065170694549559595,\n",
       " 3231: 0.01090900756590454,\n",
       " 3232: 0.00880376049178261,\n",
       " 3235: 0.011947960667419258,\n",
       " 3236: 0.008960970500564443,\n",
       " 3245: 0.01209191200076166,\n",
       " 3251: 0.00604595600038083,\n",
       " 3252: 0.01024110914350222,\n",
       " 3254: 0.008363572467193481,\n",
       " 3255: 0.007168776400451555,\n",
       " 3256: 0.016543330154888205,\n",
       " 3284: 0.00974396792294386,\n",
       " 3288: 0.003484821861330617,\n",
       " 3289: 0.008226464721829654,\n",
       " 3290: 0.011340437243652177,\n",
       " 3301: 0.003196269732685407,\n",
       " 3303: 0.011404871546172929,\n",
       " 3306: 0.003533903859377527,\n",
       " 3307: 0.0066465476560477995,\n",
       " 3312: 0.0067812749734001195,\n",
       " 3313: 0.0044408349383328214,\n",
       " 3314: 0.017794835036581875,\n",
       " 3321: 0.055245616297057855,\n",
       " 3322: 0.02255345384411725,\n",
       " 3323: 0.009936917782804136,\n",
       " 3330: 0.0030976194322938815,\n",
       " 3331: 0.005514443384962735,\n",
       " 3332: 0.01024110914350222,\n",
       " 3333: 0.017921941001128885,\n",
       " 3335: 0.003830643878103884,\n",
       " 3336: 0.0044408349383328214,\n",
       " 3340: 0.01024110914350222,\n",
       " 3341: 0.003301410184418479,\n",
       " 3342: 0.055318117105846644,\n",
       " 3353: 0.004919748510113812,\n",
       " 3354: 0.003484821861330617,\n",
       " 3355: 0.011404871546172929,\n",
       " 3357: 0.005638363461029312,\n",
       " 3358: 0.0032585347274779798,\n",
       " 3359: 0.004968458891402068,\n",
       " 3360: 0.022138868295512155,\n",
       " 3361: 0.0036363358553015133,\n",
       " 3364: 0.011340437243652177,\n",
       " 3367: 0.003662878452785466,\n",
       " 3368: 0.006690857973754785,\n",
       " 3370: 0.030229780001904148,\n",
       " 3372: 0.026411281475347832,\n",
       " 3375: 0.0037448831942657377,\n",
       " 3377: 0.003301410184418479,\n",
       " 3381: 0.0015632845733071926,\n",
       " 3397: 0.014759245530341436,\n",
       " 3400: 0.012239374342234363,\n",
       " 3401: 0.019300551847369573,\n",
       " 3404: 0.030412990789794477,\n",
       " 3406: 0.009468195245879411,\n",
       " 3407: 0.02181801513180908,\n",
       " 3409: 0.007379622765170718,\n",
       " 3413: 0.003509191244976286,\n",
       " 3416: 0.015520031382420892,\n",
       " 3473: 0.008701982913842927,\n",
       " 3487: 0.004848447807068684,\n",
       " 3491: 0.00974396792294386,\n",
       " 3496: 0.007680831857626666,\n",
       " 3497: 0.007902588157978093,\n",
       " 3501: 0.016727144934386963,\n",
       " 3516: 0.005514443384962735,\n",
       " 3579: 0.001937507135257177,\n",
       " 3635: 0.04068764984040072,\n",
       " 3636: 0.011404871546172929,\n",
       " 3639: 0.005018143480316088,\n",
       " 3647: 0.0016561529638006894,\n",
       " 3661: 0.03272702269771362,\n",
       " 3679: 0.01024110914350222,\n",
       " 3690: 0.008029029568505743,\n",
       " 3691: 0.006690857973754785,\n",
       " 3696: 0.013748338302235858,\n",
       " 3704: 0.00583505055850708,\n",
       " 3707: 0.012390477729175526,\n",
       " 3708: 0.018137868001142487,\n",
       " 3709: 0.007840849187993888,\n",
       " 3714: 0.006195238864587763,\n",
       " 3716: 0.006602820368836958,\n",
       " 3725: 0.003920424593996944,\n",
       " 3730: 0.005973980333709629,\n",
       " 3731: 0.02223228124190672,\n",
       " 3732: 0.014135615437510109,\n",
       " 3745: 0.01090900756590454,\n",
       " 3748: 0.025090717401580444,\n",
       " 3753: 0.00604595600038083,\n",
       " 3760: 0.007965307111612838,\n",
       " 3771: 0.00545450378295227,\n",
       " 3774: 0.00487198396147193,\n",
       " 3775: 0.007902588157978093,\n",
       " 3776: 0.006009752671037232,\n",
       " 3777: 0.0037730402107639762,\n",
       " 3780: 0.005173343794140297,\n",
       " 3782: 0.006602820368836958,\n",
       " 3787: 0.00506883179829908,\n",
       " 3789: 0.004363603026361816,\n",
       " 3791: 0.0036363358553015133,\n",
       " 3793: 0.012867034564913046,\n",
       " 3795: 0.003951294078989046,\n",
       " 3799: 0.024359919807359652,\n",
       " 3802: 0.022809743092345857,\n",
       " 3807: 0.01090900756590454,\n",
       " 3809: 0.012390477729175526,\n",
       " 3814: 0.017763339753331286,\n",
       " 3815: 0.004689853719921578,\n",
       " 3829: 0.005702435773086464,\n",
       " 3830: 0.009014629006555848,\n",
       " 3843: 0.007379622765170718,\n",
       " 3844: 0.0059036982121365746,\n",
       " 3852: 0.0052272327919959255,\n",
       " 3874: 0.011404871546172929,\n",
       " 3881: 0.01024110914350222,\n",
       " 3890: 0.003951294078989046,\n",
       " 3925: 0.009650275923684786,\n",
       " 3927: 0.005767981011857573,\n",
       " 3935: 0.012867034564913046,\n",
       " 3937: 0.008960970500564443,\n",
       " 3953: 0.01090900756590454,\n",
       " 3963: 0.006119687171117182,\n",
       " 3970: 0.01102888676992547,\n",
       " 3971: 0.03717143318752658,\n",
       " 3981: 0.010454465583991851,\n",
       " 4000: 0.007325756905570932,\n",
       " 4001: 0.028191817305146565,\n",
       " 4011: 0.002712509989360048,\n",
       " 4020: 0.013786108462406837,\n",
       " 4022: 0.0127579918991087,\n",
       " 4026: 0.016727144934386963,\n",
       " 4027: 0.005282256295069567,\n",
       " 4029: 0.011891335261412532,\n",
       " 4030: 0.0033678815304134823,\n",
       " 4039: 0.015054430440948265,\n",
       " 4042: 0.03974767113121654,\n",
       " 4047: 0.008505327932739132,\n",
       " 4048: 0.028271230875020217,\n",
       " 4050: 0.022469299165594425,\n",
       " 4054: 0.02181801513180908,\n",
       " 4062: 0.023895921334838515,\n",
       " 4068: 0.038601103694739146,\n",
       " 4075: 0.006195238864587763,\n",
       " 4082: 0.017010655865478265,\n",
       " 4085: 0.013562549946800239,\n",
       " 4087: 0.0065170694549559595,\n",
       " 4094: 0.01167010111701416,\n",
       " 4098: 0.008226464721829654,\n",
       " 4100: 0.009839497020227624,\n",
       " 4106: 0.003982653555806419,\n",
       " 4109: 0.004919748510113812,\n",
       " 4112: 0.007965307111612838,\n",
       " 4114: 0.00487198396147193,\n",
       " 4124: 0.004919748510113812,\n",
       " 4127: 0.002230285991251595,\n",
       " 4128: 0.0032167586412282616,\n",
       " 4132: 0.007632157384511161,\n",
       " 4133: 0.00215370964820433,\n",
       " 4140: 0.009292858296881645,\n",
       " 4141: 0.010103644591240446,\n",
       " 4143: 0.002560277285875555,\n",
       " 4144: 0.001425608943271616,\n",
       " 4145: 0.002344926859960789,\n",
       " 4147: 0.004325985758893179,\n",
       " 4148: 0.01024110914350222,\n",
       " 4150: 0.002727251891476135,\n",
       " 4151: 0.006827406095668147,\n",
       " 4152: 0.005973980333709629,\n",
       " 4158: 0.002819181730514656,\n",
       " 4160: 0.003484821861330617,\n",
       " 4162: 0.06804262346191306,\n",
       " 4163: 0.008433854588766535,\n",
       " 4165: 0.011251442780977776,\n",
       " 4167: 0.018936390491758822,\n",
       " 4168: 0.006690857973754785,\n",
       " 4169: 0.006475023845569147,\n",
       " 4170: 0.004646429148440823,\n",
       " 4171: 0.016507050922092394,\n",
       " 4178: 0.015361663715253332,\n",
       " 4179: 0.011491931634311652,\n",
       " 4180: 0.001937507135257177,\n",
       " 4181: 0.002509071740158044,\n",
       " 4183: 0.0022009401229456525,\n",
       " 4210: 0.019551208364867876,\n",
       " 4211: 0.0036101751656950278,\n",
       " 4214: 0.023522547563981665,\n",
       " 4217: 0.008881669876665643,\n",
       " 4219: 0.0033906374867000598,\n",
       " 4221: 0.006272679350395111,\n",
       " 4223: 0.004561948618469171,\n",
       " 4227: 0.014235868029265498,\n",
       " 4228: 0.007168776400451555,\n",
       " 4230: 0.004252663966369566,\n",
       " 4238: 0.005638363461029312,\n",
       " 4242: 0.00506883179829908,\n",
       " 4248: 0.003662878452785466,\n",
       " 4251: 0.00604595600038083,\n",
       " 4254: 0.007067807718755054,\n",
       " 4257: 0.002484229445701034,\n",
       " 4258: 0.0030412990789794475,\n",
       " 4259: 0.00506883179829908,\n",
       " 4265: 0.007168776400451555,\n",
       " 4266: 0.003484821861330617,\n",
       " 4269: 0.0037171433187526584,\n",
       " 4272: 0.007603247697448619,\n",
       " 4273: 0.007325756905570932,\n",
       " 4274: 0.012239374342234363,\n",
       " 4278: 0.0037730402107639762,\n",
       " 4279: 0.004689853719921578,\n",
       " 4280: 0.003004876335518616,\n",
       " 4288: 0.01024110914350222,\n",
       " 4297: 0.004689853719921578,\n",
       " 4300: 0.008602531680541866,\n",
       " 4307: 0.00583505055850708,\n",
       " 4308: 0.019808461106510876,\n",
       " 4309: 0.003951294078989046,\n",
       " 4315: 0.0027878574890644937,\n",
       " 4316: 0.002126331983184783,\n",
       " 4330: 0.004046889903480716,\n",
       " 4333: 0.01167010111701416,\n",
       " 4349: 0.003875014270514354,\n",
       " 4421: 0.026882911501693328,\n",
       " 4441: 0.012545358700790222,\n",
       " 4443: 0.004968458891402068,\n",
       " 4444: 0.004968458891402068,\n",
       " 4447: 0.0047340976229397055,\n",
       " 4454: 0.01102888676992547,\n",
       " 4455: 0.004968458891402068,\n",
       " 4461: 0.004216927294383267,\n",
       " 4466: 0.006690857973754785,\n",
       " 4471: 0.020908931167983702,\n",
       " 4474: 0.009068934000571243,\n",
       " 4479: 0.006690857973754785,\n",
       " 4480: 0.038601103694739146,\n",
       " 4483: 0.001975647039494523,\n",
       " 4485: 0.016978680948437894,\n",
       " 4486: 0.013441455750846664,\n",
       " 4489: 0.007168776400451555,\n",
       " 4490: 0.003920424593996944,\n",
       " 4501: 0.012950047691138293,\n",
       " 4503: 0.015930614223225677,\n",
       " 4543: 0.01858571659376329,\n",
       " 4564: 0.01013766359659816,\n",
       " 4565: 0.017303943035572717,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "tf_idf.inverted_index['one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0                                                 make\n",
       "0             {3: 4, 6: 1, 8: 10, 9: 6, 11: 1, 15: 1, 23: 1,...\n",
       "Name: 190, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "pd.read_csv('bow.csv').iloc[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Unnamed: 0                                                 make\n",
       "0             {3: 4, 6: 1, 8: 10, 9: 6, 11: 1, 15: 1, 23: 1,...\n",
       "Name: 190, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "pd.read_csv('bow.csv').iloc[190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 1038: 0.004561948618469171,\n",
       " 1040: 0.0034137030478340736,\n",
       " 1046: 0.004014514784252871,\n",
       " 1047: 0.0035843882002257773,\n",
       " 1048: 0.017669519296887638,\n",
       " 1055: 0.006272679350395111,\n",
       " 1057: 0.002900660971280976,\n",
       " 1068: 0.024934874436353234,\n",
       " 1072: 0.012019505342074464,\n",
       " 1073: 0.007720220738947829,\n",
       " 1083: 0.039917050411605245,\n",
       " 1084: 0.007750028541028708,\n",
       " 1086: 0.025734069129826093,\n",
       " 1089: 0.004825137961842393,\n",
       " 1094: 0.001613550958300993,\n",
       " 1095: 0.01024110914350222,\n",
       " 1101: 0.004014514784252871,\n",
       " 1108: 0.010325398107646273,\n",
       " 1115: 0.01645292944365931,\n",
       " 1116: 0.009157196131963665,\n",
       " 1211: 0.012390477729175526,\n",
       " 1248: 0.015930614223225677,\n",
       " 1279: 0.027125099893600478,\n",
       " 1308: 0.0020908931167983704,\n",
       " 1320: 0.029272503635177183,\n",
       " 1321: 0.004079791447411454,\n",
       " 1325: 0.00487198396147193,\n",
       " 1327: 0.002819181730514656,\n",
       " 1329: 0.00880376049178261,\n",
       " 1331: 0.0059036982121365746,\n",
       " 1349: 0.017010655865478265,\n",
       " 1355: 0.0029518491060682873,\n",
       " 1358: 0.00512055457175111,\n",
       " 1360: 0.03386477195305336,\n",
       " 1364: 0.007720220738947829,\n",
       " 1365: 0.00583505055850708,\n",
       " 1366: 0.003662878452785466,\n",
       " 1368: 0.00506883179829908,\n",
       " 1369: 0.005575714978128987,\n",
       " 1374: 0.008505327932739132,\n",
       " 1379: 0.00974396792294386,\n",
       " 1380: 0.027572216924813674,\n",
       " 1385: 0.010103644591240446,\n",
       " 1386: 0.004113232360914827,\n",
       " 1387: 0.002509071740158044,\n",
       " 1388: 0.005282256295069567,\n",
       " 1389: 0.006475023845569147,\n",
       " 1394: 0.004289011521637683,\n",
       " 1399: 0.015206495394897239,\n",
       " 1400: 0.007379622765170718,\n",
       " 1402: 0.006602820368836958,\n",
       " 1403: 0.00604595600038083,\n",
       " 1404: 0.012390477729175526,\n",
       " 1405: 0.005395853204640956,\n",
       " 1406: 0.006119687171117182,\n",
       " 1408: 0.006874169151117929,\n",
       " 1411: 0.007067807718755054,\n",
       " 1413: 0.007661287756207768,\n",
       " 1415: 0.005338450510974562,\n",
       " 1427: 0.004325985758893179,\n",
       " 1429: 0.005702435773086464,\n",
       " 1430: 0.03744883194265737,\n",
       " 1432: 0.011404871546172929,\n",
       " 1433: 0.013205640737673916,\n",
       " 1436: 0.040145147842528706,\n",
       " 1437: 0.009123897236938343,\n",
       " 1438: 0.03136339675197555,\n",
       " 1439: 0.006690857973754785,\n",
       " 1474: 0.027125099893600478,\n",
       " 1480: 0.010676901021949124,\n",
       " 1482: 0.00604595600038083,\n",
       " 1483: 0.007168776400451555,\n",
       " 1484: 0.01209191200076166,\n",
       " 1485: 0.00487198396147193,\n",
       " 1486: 0.020072573921264353,\n",
       " 1487: 0.0065170694549559595,\n",
       " 1490: 0.014615951884415793,\n",
       " 1491: 0.017303943035572717,\n",
       " 1493: 0.004401880245891305,\n",
       " 1494: 0.006690857973754785,\n",
       " 1497: 0.015520031382420892,\n",
       " 1498: 0.012043544352758612,\n",
       " 1502: 0.0034370845755589646,\n",
       " 1503: 0.012545358700790222,\n",
       " 1508: 0.045619486184691714,\n",
       " 1509: 0.015520031382420892,\n",
       " 1534: 0.017921941001128885,\n",
       " 1552: 0.0029869901668548144,\n",
       " 1553: 0.011535962023715146,\n",
       " 1554: 0.005767981011857573,\n",
       " 1564: 0.004779184266967704,\n",
       " 1565: 0.016727144934386963,\n",
       " 1569: 0.007720220738947829,\n",
       " 1570: 0.01024110914350222,\n",
       " 1582: 0.006488978638339769,\n",
       " 1585: 0.006488978638339769,\n",
       " 1587: 0.009613301686429288,\n",
       " 1588: 0.0008651971517786359,\n",
       " 1589: 0.001005639976015248,\n",
       " 1590: 0.001482464839088948,\n",
       " 1593: 0.01576380150884635,\n",
       " 1594: 0.0017424109306653085,\n",
       " 1601: 0.02805173374089739,\n",
       " 1607: 0.005767981011857573,\n",
       " 1610: 0.03501030335104248,\n",
       " 1611: 0.005200148684265377,\n",
       " 1614: 0.005926941118483569,\n",
       " 1615: 0.0031072095853350397,\n",
       " 1616: 0.0034607886071145438,\n",
       " 1618: 0.002484229445701034,\n",
       " 1644: 0.004401880245891305,\n",
       " 1645: 0.0027572216924813676,\n",
       " 1646: 0.005670218621826088,\n",
       " 1656: 0.01090900756590454,\n",
       " 1658: 0.0033906374867000598,\n",
       " 1662: 0.029518491060682873,\n",
       " 1664: 0.014135615437510109,\n",
       " 1670: 0.004046889903480716,\n",
       " 1672: 0.003196269732685407,\n",
       " 1675: 0.002900660971280976,\n",
       " 1678: 0.013562549946800239,\n",
       " 1681: 0.010036286960632176,\n",
       " 1682: 0.0033232738280238997,\n",
       " 1683: 0.002742154907276551,\n",
       " 1686: 0.020072573921264353,\n",
       " 1687: 0.004689853719921578,\n",
       " 1689: 0.007067807718755054,\n",
       " 1691: 0.006119687171117182,\n",
       " 1697: 0.007489766388531475,\n",
       " 1700: 0.00604595600038083,\n",
       " 1704: 0.00875257583776062,\n",
       " 1705: 0.015681698375987776,\n",
       " 1706: 0.003059843585558591,\n",
       " 1717: 0.004363603026361816,\n",
       " 1731: 0.0035716323703317353,\n",
       " 1737: 0.005606864223816859,\n",
       " 1739: 0.0036363358553015133,\n",
       " 1743: 0.006602820368836958,\n",
       " 1752: 0.007272671710603027,\n",
       " 1758: 0.007780067411342773,\n",
       " 1789: 0.007489766388531475,\n",
       " 1820: 0.006874169151117929,\n",
       " 1821: 0.011404871546172929,\n",
       " 1822: 0.009379707439843156,\n",
       " 1827: 0.00512055457175111,\n",
       " 1830: 0.01858571659376329,\n",
       " 1860: 0.01024110914350222,\n",
       " 1868: 0.02230285991251595,\n",
       " 1872: 0.005702435773086464,\n",
       " 1881: 0.005338450510974562,\n",
       " 1890: 0.0034607886071145438,\n",
       " 1966: 0.004147226016790156,\n",
       " 1974: 0.01433755280090311,\n",
       " 1979: 0.008960970500564443,\n",
       " 1980: 0.012545358700790222,\n",
       " 1986: 0.012239374342234363,\n",
       " 1989: 0.006690857973754785,\n",
       " 1994: 0.024478748684468726,\n",
       " 2001: 0.028839905059287865,\n",
       " 2004: 0.020072573921264353,\n",
       " 2006: 0.007325756905570932,\n",
       " 2007: 0.00487198396147193,\n",
       " 2010: 0.016187559613922865,\n",
       " 2012: 0.026411281475347832,\n",
       " 2013: 0.010676901021949124,\n",
       " 2015: 0.020072573921264353,\n",
       " 2016: 0.006272679350395111,\n",
       " 2017: 0.004363603026361816,\n",
       " 2018: 0.004113232360914827,\n",
       " 2020: 0.006119687171117182,\n",
       " 2021: 0.00757455619670353,\n",
       " 2024: 0.0065170694549559595,\n",
       " 2026: 0.03028190031225226,\n",
       " 2028: 0.00583505055850708,\n",
       " 2029: 0.014759245530341436,\n",
       " 2030: 0.004181786233596741,\n",
       " 2032: 0.011404871546172929,\n",
       " 2033: 0.004147226016790156,\n",
       " 2036: 0.0026834991873348063,\n",
       " 2039: 0.002023444951740358,\n",
       " 2043: 0.004480485250282221,\n",
       " 2047: 0.002851217886543232,\n",
       " 2052: 0.004325985758893179,\n",
       " 2053: 0.009292858296881645,\n",
       " 2080: 0.010676901021949124,\n",
       " 2084: 0.026411281475347832,\n",
       " 2090: 0.00604595600038083,\n",
       " 2091: 0.004779184266967704,\n",
       " 2103: 0.010346687588280595,\n",
       " 2104: 0.023895921334838515,\n",
       " 2105: 0.003022978000190415,\n",
       " 2106: 0.0052272327919959255,\n",
       " 2111: 0.025955914553359077,\n",
       " 2112: 0.012704160709660984,\n",
       " 2115: 0.004968458891402068,\n",
       " 2118: 0.0028034321119084294,\n",
       " 2125: 0.003509191244976286,\n",
       " 2127: 0.0066465476560477995,\n",
       " 2128: 0.030229780001904148,\n",
       " 2134: 0.0059036982121365746,\n",
       " 2135: 0.010036286960632176,\n",
       " 2152: 0.036242147357838414,\n",
       " 2153: 0.0047340976229397055,\n",
       " 2196: 0.050816642838643934,\n",
       " 2198: 0.009839497020227624,\n",
       " 2199: 0.005338450510974562,\n",
       " 2200: 0.028139122319529468,\n",
       " 2201: 0.00971253576835372,\n",
       " 2203: 0.0037171433187526584,\n",
       " 2211: 0.011491931634311652,\n",
       " 2212: 0.0059036982121365746,\n",
       " 2217: 0.07806000969380582,\n",
       " 2218: 0.0038900337056713865,\n",
       " 2219: 0.005514443384962735,\n",
       " 2224: 0.009528120532245738,\n",
       " 2225: 0.007902588157978093,\n",
       " 2228: 0.00512055457175111,\n",
       " 2231: 0.0047340976229397055,\n",
       " 2233: 0.004919748510113812,\n",
       " 2238: 0.007965307111612838,\n",
       " 2243: 0.01858571659376329,\n",
       " 2245: 0.007902588157978093,\n",
       " 2251: 0.009041699964533493,\n",
       " 2253: 0.007489766388531475,\n",
       " 2257: 0.0052272327919959255,\n",
       " 2258: 0.008433854588766535,\n",
       " 2259: 0.009839497020227624,\n",
       " 2261: 0.01024110914350222,\n",
       " 2264: 0.004603801358088155,\n",
       " 2265: 0.0052272327919959255,\n",
       " 2272: 0.0026551023705376126,\n",
       " 2275: 0.015206495394897239,\n",
       " 2276: 0.0033678815304134823,\n",
       " 2280: 0.01967899404045525,\n",
       " 2285: 0.005638363461029312,\n",
       " 2290: 0.014069561159764734,\n",
       " 2291: 0.018083399929066987,\n",
       " 2292: 0.004520849982266747,\n",
       " 2296: 0.00458277943407862,\n",
       " 2298: 0.00968130574980596,\n",
       " 2299: 0.0017921941001128887,\n",
       " 2301: 0.0033454289868773924,\n",
       " 2302: 0.001015818518282609,\n",
       " 2305: 0.003830643878103884,\n",
       " 2306: 0.0022604249911333733,\n",
       " 2307: 0.017763339753331286,\n",
       " 2310: 0.0017794835036581873,\n",
       " 2311: 0.0016345744235557293,\n",
       " 2312: 0.003176040177415246,\n",
       " 2313: 0.001158924591297018,\n",
       " 2315: 0.0017424109306653085,\n",
       " 2316: 0.00201531866679361,\n",
       " 2317: 0.0026136163959979627,\n",
       " 2320: 0.001158924591297018,\n",
       " 2321: 0.007517817948039084,\n",
       " 2322: 0.0017068515239170368,\n",
       " 2323: 0.001960212296998472,\n",
       " 2324: 0.007018382489952572,\n",
       " 2326: 0.001937507135257177,\n",
       " 2328: 0.0016292673637389899,\n",
       " 2329: 0.0019913267779032096,\n",
       " 2330: 0.001588020088707623,\n",
       " 2331: 0.003905170023592287,\n",
       " 2333: 0.00500562940679909,\n",
       " 2335: 0.0031363396751975556,\n",
       " 2338: 0.004113232360914827,\n",
       " 2339: 0.0033566177125860124,\n",
       " 2340: 0.004575814723692482,\n",
       " 2341: 0.002521680140862356,\n",
       " 2342: 0.05018143480316089,\n",
       " 2343: 0.001754595622488143,\n",
       " 2344: 0.0038160786922555806,\n",
       " 2346: 0.008093779806961432,\n",
       " 2348: 0.02181801513180908,\n",
       " 2350: 0.005514443384962735,\n",
       " 2353: 0.0017731955760834236,\n",
       " 2355: 0.0029518491060682873,\n",
       " 2359: 0.0022604249911333733,\n",
       " 2365: 0.004313590384225864,\n",
       " 2368: 0.006969643722661234,\n",
       " 2371: 0.004749031684841724,\n",
       " 2374: 0.00215370964820433,\n",
       " 2377: 0.00880376049178261,\n",
       " 2405: 0.0034370845755589646,\n",
       " 2407: 0.005018143480316088,\n",
       " 2409: 0.00974396792294386,\n",
       " 2416: 0.060621867547442684,\n",
       " 2429: 0.007840849187993888,\n",
       " 2432: 0.0066465476560477995,\n",
       " 2438: 0.003951294078989046,\n",
       " 2443: 0.003022978000190415,\n",
       " 2444: 0.0432598575889318,\n",
       " 2446: 0.003951294078989046,\n",
       " 2448: 0.0038900337056713865,\n",
       " 2463: 0.010676901021949124,\n",
       " 2465: 0.027878574890644936,\n",
       " 2466: 0.022469299165594425,\n",
       " 2481: 0.008505327932739132,\n",
       " 2484: 0.011404871546172929,\n",
       " 2485: 0.005338450510974562,\n",
       " 2496: 0.006119687171117182,\n",
       " 2497: 0.015440441477895658,\n",
       " 2498: 0.09694140814246989,\n",
       " 2499: 0.03717143318752658,\n",
       " 2500: 0.017010655865478265,\n",
       " 2508: 0.007603247697448619,\n",
       " 2590: 0.00604595600038083,\n",
       " 2596: 0.02205777353985094,\n",
       " 2597: 0.017156046086550733,\n",
       " 2598: 0.028139122319529468,\n",
       " 2631: 0.015681698375987776,\n",
       " 2654: 0.007489766388531475,\n",
       " 2658: 0.008881669876665643,\n",
       " 2659: 0.006602820368836958,\n",
       " 2661: 0.02418382400152332,\n",
       " 2663: 0.0025472809544751715,\n",
       " 2695: 0.020072573921264353,\n",
       " 2697: 0.002126331983184783,\n",
       " 2702: 0.022809743092345857,\n",
       " 2713: 0.011151429956257975,\n",
       " 2730: 0.00512055457175111,\n",
       " 2738: 0.034607886071145434,\n",
       " 2751: 0.014135615437510109,\n",
       " 2799: 0.003982653555806419,\n",
       " 2803: 0.001960212296998472,\n",
       " 2805: 0.009258567306856251,\n",
       " 2806: 0.0016452929443659307,\n",
       " 2807: 0.001915321939051942,\n",
       " 2808: 0.0030412990789794475,\n",
       " 2809: 0.0021629928794465896,\n",
       " 2810: 0.0017303943035572719,\n",
       " 2811: 0.05822155419151263,\n",
       " 2812: 0.008181755674428404,\n",
       " 2814: 0.0037448831942657377,\n",
       " 2815: 0.013939287445322468,\n",
       " 2816: 0.012961994229598752,\n",
       " 2819: 0.016938880946214645,\n",
       " 2820: 0.002126331983184783,\n",
       " 2822: 0.0016783088562930062,\n",
       " 2824: 0.0049439837244493485,\n",
       " 2826: 0.015406580860619568,\n",
       " 2828: 0.004507314503277924,\n",
       " 2829: 0.002521680140862356,\n",
       " 2831: 0.002509071740158044,\n",
       " 2832: 0.0023019006790440774,\n",
       " 2833: 0.004046889903480716,\n",
       " 2835: 0.004603801358088155,\n",
       " 2836: 0.001915321939051942,\n",
       " 2838: 0.002851217886543232,\n",
       " 2840: 0.002772454961500601,\n",
       " 2841: 0.005043360281724712,\n",
       " 2842: 0.007434286637505317,\n",
       " 2843: 0.0022809743092345857,\n",
       " 2844: 0.004646429148440823,\n",
       " 2846: 0.0016083793206141308,\n",
       " 2847: 0.0022204174691664107,\n",
       " 2848: 0.009839497020227624,\n",
       " 2850: 0.0047118718125033696,\n",
       " 2853: 0.0017244479313800992,\n",
       " 2859: 0.015440441477895658,\n",
       " 2861: 0.007965307111612838,\n",
       " 2863: 0.004480485250282221,\n",
       " 2867: 0.03136339675197555,\n",
       " 2868: 0.017303943035572717,\n",
       " 2870: 0.014759245530341436,\n",
       " 2871: 0.027125099893600478,\n",
       " 2872: 0.021353802043898248,\n",
       " 2873: 0.011404871546172929,\n",
       " 2917: 0.008505327932739132,\n",
       " 2931: 0.005702435773086464,\n",
       " 2939: 0.007168776400451555,\n",
       " 2941: 0.0047340976229397055,\n",
       " 2942: 0.0052272327919959255,\n",
       " 2955: 0.006352080354830492,\n",
       " 2956: 0.012624260327839218,\n",
       " 2961: 0.01090900756590454,\n",
       " 2962: 0.0066465476560477995,\n",
       " 2968: 0.0038900337056713865,\n",
       " 2973: 0.012390477729175526,\n",
       " 2980: 0.018818038051185332,\n",
       " 2982: 0.00604595600038083,\n",
       " 2983: 0.00487198396147193,\n",
       " 2984: 0.010103644591240446,\n",
       " 2985: 0.006119687171117182,\n",
       " 2988: 0.006272679350395111,\n",
       " 3001: 0.01090900756590454,\n",
       " 3004: 0.012239374342234363,\n",
       " 3006: 0.09558368533935406,\n",
       " 3007: 0.007780067411342773,\n",
       " 3009: 0.00880376049178261,\n",
       " 3011: 0.007720220738947829,\n",
       " 3013: 0.003920424593996944,\n",
       " 3015: 0.009936917782804136,\n",
       " 3017: 0.006272679350395111,\n",
       " 3022: 0.002389592133483852,\n",
       " 3030: 0.013562549946800239,\n",
       " 3041: 0.007965307111612838,\n",
       " 3043: 0.006119687171117182,\n",
       " 3046: 0.011046227786859314,\n",
       " 3051: 0.01013766359659816,\n",
       " 3052: 0.0034607886071145438,\n",
       " 3057: 0.005638363461029312,\n",
       " 3058: 0.00604595600038083,\n",
       " 3059: 0.009292858296881645,\n",
       " 3062: 0.015440441477895658,\n",
       " 3066: 0.007603247697448619,\n",
       " 3070: 0.01102888676992547,\n",
       " 3071: 0.004561948618469171,\n",
       " 3073: 0.0033906374867000598,\n",
       " 3074: 0.005514443384962735,\n",
       " 3075: 0.026411281475347832,\n",
       " 3076: 0.004363603026361816,\n",
       " 3079: 0.003496964097781246,\n",
       " 3084: 0.017454412105447265,\n",
       " 3085: 0.007379622765170718,\n",
       " 3090: 0.0066465476560477995,\n",
       " 3096: 0.010454465583991851,\n",
       " 3097: 0.00512055457175111,\n",
       " 3098: 0.010988635358356398,\n",
       " 3099: 0.02042267695477478,\n",
       " 3100: 0.002424223903534342,\n",
       " 3101: 0.009041699964533493,\n",
       " 3103: 0.0031560650819598044,\n",
       " 3104: 0.003004876335518616,\n",
       " 3105: 0.02664500962999693,\n",
       " 3108: 0.007168776400451555,\n",
       " 3109: 0.005767981011857573,\n",
       " 3112: 0.012867034564913046,\n",
       " 3114: 0.02069337517656119,\n",
       " 3115: 0.017303943035572717,\n",
       " 3127: 0.013205640737673916,\n",
       " 3146: 0.018247794473876686,\n",
       " 3153: 0.014759245530341436,\n",
       " 3158: 0.007780067411342773,\n",
       " 3159: 0.004216927294383267,\n",
       " 3160: 0.009379707439843156,\n",
       " 3161: 0.00506883179829908,\n",
       " 3163: 0.005767981011857573,\n",
       " 3166: 0.013322504814998465,\n",
       " 3173: 0.038601103694739146,\n",
       " 3196: 0.005282256295069567,\n",
       " 3204: 0.014759245530341436,\n",
       " 3215: 0.004401880245891305,\n",
       " 3216: 0.007720220738947829,\n",
       " 3219: 0.021506329201354667,\n",
       " 3224: 0.009123897236938343,\n",
       " 3229: 0.0065170694549559595,\n",
       " 3231: 0.01090900756590454,\n",
       " 3232: 0.00880376049178261,\n",
       " 3235: 0.011947960667419258,\n",
       " 3236: 0.008960970500564443,\n",
       " 3245: 0.01209191200076166,\n",
       " 3251: 0.00604595600038083,\n",
       " 3252: 0.01024110914350222,\n",
       " 3254: 0.008363572467193481,\n",
       " 3255: 0.007168776400451555,\n",
       " 3256: 0.016543330154888205,\n",
       " 3284: 0.00974396792294386,\n",
       " 3288: 0.003484821861330617,\n",
       " 3289: 0.008226464721829654,\n",
       " 3290: 0.011340437243652177,\n",
       " 3301: 0.003196269732685407,\n",
       " 3303: 0.011404871546172929,\n",
       " 3306: 0.003533903859377527,\n",
       " 3307: 0.0066465476560477995,\n",
       " 3312: 0.0067812749734001195,\n",
       " 3313: 0.0044408349383328214,\n",
       " 3314: 0.017794835036581875,\n",
       " 3321: 0.055245616297057855,\n",
       " 3322: 0.02255345384411725,\n",
       " 3323: 0.009936917782804136,\n",
       " 3330: 0.0030976194322938815,\n",
       " 3331: 0.005514443384962735,\n",
       " 3332: 0.01024110914350222,\n",
       " 3333: 0.017921941001128885,\n",
       " 3335: 0.003830643878103884,\n",
       " 3336: 0.0044408349383328214,\n",
       " 3340: 0.01024110914350222,\n",
       " 3341: 0.003301410184418479,\n",
       " 3342: 0.055318117105846644,\n",
       " 3353: 0.004919748510113812,\n",
       " 3354: 0.003484821861330617,\n",
       " 3355: 0.011404871546172929,\n",
       " 3357: 0.005638363461029312,\n",
       " 3358: 0.0032585347274779798,\n",
       " 3359: 0.004968458891402068,\n",
       " 3360: 0.022138868295512155,\n",
       " 3361: 0.0036363358553015133,\n",
       " 3364: 0.011340437243652177,\n",
       " 3367: 0.003662878452785466,\n",
       " 3368: 0.006690857973754785,\n",
       " 3370: 0.030229780001904148,\n",
       " 3372: 0.026411281475347832,\n",
       " 3375: 0.0037448831942657377,\n",
       " 3377: 0.003301410184418479,\n",
       " 3381: 0.0015632845733071926,\n",
       " 3397: 0.014759245530341436,\n",
       " 3400: 0.012239374342234363,\n",
       " 3401: 0.019300551847369573,\n",
       " 3404: 0.030412990789794477,\n",
       " 3406: 0.009468195245879411,\n",
       " 3407: 0.02181801513180908,\n",
       " 3409: 0.007379622765170718,\n",
       " 3413: 0.003509191244976286,\n",
       " 3416: 0.015520031382420892,\n",
       " 3473: 0.008701982913842927,\n",
       " 3487: 0.004848447807068684,\n",
       " 3491: 0.00974396792294386,\n",
       " 3496: 0.007680831857626666,\n",
       " 3497: 0.007902588157978093,\n",
       " 3501: 0.016727144934386963,\n",
       " 3516: 0.005514443384962735,\n",
       " 3579: 0.001937507135257177,\n",
       " 3635: 0.04068764984040072,\n",
       " 3636: 0.011404871546172929,\n",
       " 3639: 0.005018143480316088,\n",
       " 3647: 0.0016561529638006894,\n",
       " 3661: 0.03272702269771362,\n",
       " 3679: 0.01024110914350222,\n",
       " 3690: 0.008029029568505743,\n",
       " 3691: 0.006690857973754785,\n",
       " 3696: 0.013748338302235858,\n",
       " 3704: 0.00583505055850708,\n",
       " 3707: 0.012390477729175526,\n",
       " 3708: 0.018137868001142487,\n",
       " 3709: 0.007840849187993888,\n",
       " 3714: 0.006195238864587763,\n",
       " 3716: 0.006602820368836958,\n",
       " 3725: 0.003920424593996944,\n",
       " 3730: 0.005973980333709629,\n",
       " 3731: 0.02223228124190672,\n",
       " 3732: 0.014135615437510109,\n",
       " 3745: 0.01090900756590454,\n",
       " 3748: 0.025090717401580444,\n",
       " 3753: 0.00604595600038083,\n",
       " 3760: 0.007965307111612838,\n",
       " 3771: 0.00545450378295227,\n",
       " 3774: 0.00487198396147193,\n",
       " 3775: 0.007902588157978093,\n",
       " 3776: 0.006009752671037232,\n",
       " 3777: 0.0037730402107639762,\n",
       " 3780: 0.005173343794140297,\n",
       " 3782: 0.006602820368836958,\n",
       " 3787: 0.00506883179829908,\n",
       " 3789: 0.004363603026361816,\n",
       " 3791: 0.0036363358553015133,\n",
       " 3793: 0.012867034564913046,\n",
       " 3795: 0.003951294078989046,\n",
       " 3799: 0.024359919807359652,\n",
       " 3802: 0.022809743092345857,\n",
       " 3807: 0.01090900756590454,\n",
       " 3809: 0.012390477729175526,\n",
       " 3814: 0.017763339753331286,\n",
       " 3815: 0.004689853719921578,\n",
       " 3829: 0.005702435773086464,\n",
       " 3830: 0.009014629006555848,\n",
       " 3843: 0.007379622765170718,\n",
       " 3844: 0.0059036982121365746,\n",
       " 3852: 0.0052272327919959255,\n",
       " 3874: 0.011404871546172929,\n",
       " 3881: 0.01024110914350222,\n",
       " 3890: 0.003951294078989046,\n",
       " 3925: 0.009650275923684786,\n",
       " 3927: 0.005767981011857573,\n",
       " 3935: 0.012867034564913046,\n",
       " 3937: 0.008960970500564443,\n",
       " 3953: 0.01090900756590454,\n",
       " 3963: 0.006119687171117182,\n",
       " 3970: 0.01102888676992547,\n",
       " 3971: 0.03717143318752658,\n",
       " 3981: 0.010454465583991851,\n",
       " 4000: 0.007325756905570932,\n",
       " 4001: 0.028191817305146565,\n",
       " 4011: 0.002712509989360048,\n",
       " 4020: 0.013786108462406837,\n",
       " 4022: 0.0127579918991087,\n",
       " 4026: 0.016727144934386963,\n",
       " 4027: 0.005282256295069567,\n",
       " 4029: 0.011891335261412532,\n",
       " 4030: 0.0033678815304134823,\n",
       " 4039: 0.015054430440948265,\n",
       " 4042: 0.03974767113121654,\n",
       " 4047: 0.008505327932739132,\n",
       " 4048: 0.028271230875020217,\n",
       " 4050: 0.022469299165594425,\n",
       " 4054: 0.02181801513180908,\n",
       " 4062: 0.023895921334838515,\n",
       " 4068: 0.038601103694739146,\n",
       " 4075: 0.006195238864587763,\n",
       " 4082: 0.017010655865478265,\n",
       " 4085: 0.013562549946800239,\n",
       " 4087: 0.0065170694549559595,\n",
       " 4094: 0.01167010111701416,\n",
       " 4098: 0.008226464721829654,\n",
       " 4100: 0.009839497020227624,\n",
       " 4106: 0.003982653555806419,\n",
       " 4109: 0.004919748510113812,\n",
       " 4112: 0.007965307111612838,\n",
       " 4114: 0.00487198396147193,\n",
       " 4124: 0.004919748510113812,\n",
       " 4127: 0.002230285991251595,\n",
       " 4128: 0.0032167586412282616,\n",
       " 4132: 0.007632157384511161,\n",
       " 4133: 0.00215370964820433,\n",
       " 4140: 0.009292858296881645,\n",
       " 4141: 0.010103644591240446,\n",
       " 4143: 0.002560277285875555,\n",
       " 4144: 0.001425608943271616,\n",
       " 4145: 0.002344926859960789,\n",
       " 4147: 0.004325985758893179,\n",
       " 4148: 0.01024110914350222,\n",
       " 4150: 0.002727251891476135,\n",
       " 4151: 0.006827406095668147,\n",
       " 4152: 0.005973980333709629,\n",
       " 4158: 0.002819181730514656,\n",
       " 4160: 0.003484821861330617,\n",
       " 4162: 0.06804262346191306,\n",
       " 4163: 0.008433854588766535,\n",
       " 4165: 0.011251442780977776,\n",
       " 4167: 0.018936390491758822,\n",
       " 4168: 0.006690857973754785,\n",
       " 4169: 0.006475023845569147,\n",
       " 4170: 0.004646429148440823,\n",
       " 4171: 0.016507050922092394,\n",
       " 4178: 0.015361663715253332,\n",
       " 4179: 0.011491931634311652,\n",
       " 4180: 0.001937507135257177,\n",
       " 4181: 0.002509071740158044,\n",
       " 4183: 0.0022009401229456525,\n",
       " 4210: 0.019551208364867876,\n",
       " 4211: 0.0036101751656950278,\n",
       " 4214: 0.023522547563981665,\n",
       " 4217: 0.008881669876665643,\n",
       " 4219: 0.0033906374867000598,\n",
       " 4221: 0.006272679350395111,\n",
       " 4223: 0.004561948618469171,\n",
       " 4227: 0.014235868029265498,\n",
       " 4228: 0.007168776400451555,\n",
       " 4230: 0.004252663966369566,\n",
       " 4238: 0.005638363461029312,\n",
       " 4242: 0.00506883179829908,\n",
       " 4248: 0.003662878452785466,\n",
       " 4251: 0.00604595600038083,\n",
       " 4254: 0.007067807718755054,\n",
       " 4257: 0.002484229445701034,\n",
       " 4258: 0.0030412990789794475,\n",
       " 4259: 0.00506883179829908,\n",
       " 4265: 0.007168776400451555,\n",
       " 4266: 0.003484821861330617,\n",
       " 4269: 0.0037171433187526584,\n",
       " 4272: 0.007603247697448619,\n",
       " 4273: 0.007325756905570932,\n",
       " 4274: 0.012239374342234363,\n",
       " 4278: 0.0037730402107639762,\n",
       " 4279: 0.004689853719921578,\n",
       " 4280: 0.003004876335518616,\n",
       " 4288: 0.01024110914350222,\n",
       " 4297: 0.004689853719921578,\n",
       " 4300: 0.008602531680541866,\n",
       " 4307: 0.00583505055850708,\n",
       " 4308: 0.019808461106510876,\n",
       " 4309: 0.003951294078989046,\n",
       " 4315: 0.0027878574890644937,\n",
       " 4316: 0.002126331983184783,\n",
       " 4330: 0.004046889903480716,\n",
       " 4333: 0.01167010111701416,\n",
       " 4349: 0.003875014270514354,\n",
       " 4421: 0.026882911501693328,\n",
       " 4441: 0.012545358700790222,\n",
       " 4443: 0.004968458891402068,\n",
       " 4444: 0.004968458891402068,\n",
       " 4447: 0.0047340976229397055,\n",
       " 4454: 0.01102888676992547,\n",
       " 4455: 0.004968458891402068,\n",
       " 4461: 0.004216927294383267,\n",
       " 4466: 0.006690857973754785,\n",
       " 4471: 0.020908931167983702,\n",
       " 4474: 0.009068934000571243,\n",
       " 4479: 0.006690857973754785,\n",
       " 4480: 0.038601103694739146,\n",
       " 4483: 0.001975647039494523,\n",
       " 4485: 0.016978680948437894,\n",
       " 4486: 0.013441455750846664,\n",
       " 4489: 0.007168776400451555,\n",
       " 4490: 0.003920424593996944,\n",
       " 4501: 0.012950047691138293,\n",
       " 4503: 0.015930614223225677,\n",
       " 4543: 0.01858571659376329,\n",
       " 4564: 0.01013766359659816,\n",
       " 4565: 0.017303943035572717,\n",
       " ...}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "tf_idf.inverted_index['one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2656"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "tf_idf.unigram_count['do']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dr = DocumentRetriever(tf_idf)\n",
    "query = \"Better stop dreaming of the quiet life, 'cause it's the one we'll never know And quit running for that runaway bus 'cause those rosy days are few And stop apologizing for the things you've never done 'Cause time is short and life is cruel but it's up to us to change This town called malice\"\n",
    "query = dr.sentence_preprocesser(query)\n",
    "query = [word for word in query if word in dr.vocab] # filter nan \n",
    "query_bow = dr.reduce_query_to_counts(query)\n",
    "relavant_documents = {word : dr.inverted_index.get(word) for word in query}\n",
    "#relavant_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lyrics copy.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-dc9b9a3b9b91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlyrics_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lyrics copy.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lyrics copy.csv'"
     ]
    }
   ],
   "source": [
    "lyrics_data = pd.read_csv('lyrics copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362232</th>\n",
       "      <td>362232</td>\n",
       "      <td>who-am-i-drinking-tonight</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I gotta say\\nBoy, after only just a couple of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362233</th>\n",
       "      <td>362233</td>\n",
       "      <td>liar</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I helped you find her diamond ring\\nYou made m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362234</th>\n",
       "      <td>362234</td>\n",
       "      <td>last-supper</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>Look at the couple in the corner booth\\nLooks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362235</th>\n",
       "      <td>362235</td>\n",
       "      <td>christ-alone-live-in-studio</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>When I fly off this mortal earth\\nAnd I'm meas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362236</th>\n",
       "      <td>362236</td>\n",
       "      <td>amen</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I heard from a friend of a friend of a friend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362237 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                         song  year           artist    genre  \\\n",
       "0            0                    ego-remix  2009  beyonce-knowles      Pop   \n",
       "1            1                 then-tell-me  2009  beyonce-knowles      Pop   \n",
       "2            2                      honesty  2009  beyonce-knowles      Pop   \n",
       "3            3              you-are-my-rock  2009  beyonce-knowles      Pop   \n",
       "4            4                black-culture  2009  beyonce-knowles      Pop   \n",
       "...        ...                          ...   ...              ...      ...   \n",
       "362232  362232    who-am-i-drinking-tonight  2012       edens-edge  Country   \n",
       "362233  362233                         liar  2012       edens-edge  Country   \n",
       "362234  362234                  last-supper  2012       edens-edge  Country   \n",
       "362235  362235  christ-alone-live-in-studio  2012       edens-edge  Country   \n",
       "362236  362236                         amen  2012       edens-edge  Country   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1       playin' everything so easy,\\nit's like you see...  \n",
       "2       If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3       Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4       Party the people, the people the party it's po...  \n",
       "...                                                   ...  \n",
       "362232  I gotta say\\nBoy, after only just a couple of ...  \n",
       "362233  I helped you find her diamond ring\\nYou made m...  \n",
       "362234  Look at the couple in the corner booth\\nLooks ...  \n",
       "362235  When I fly off this mortal earth\\nAnd I'm meas...  \n",
       "362236  I heard from a friend of a friend of a friend ...  \n",
       "\n",
       "[362237 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 'paul-weller' in lyrics_data.artist.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2007"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data.year[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13581</th>\n",
       "      <td>13581</td>\n",
       "      <td>self-inflicted</td>\n",
       "      <td>2000</td>\n",
       "      <td>divine-empire</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13582</th>\n",
       "      <td>13582</td>\n",
       "      <td>birth-of-legends</td>\n",
       "      <td>2000</td>\n",
       "      <td>divine-empire</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13583</th>\n",
       "      <td>13583</td>\n",
       "      <td>dead-and-martyred</td>\n",
       "      <td>2000</td>\n",
       "      <td>divine-empire</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13584</th>\n",
       "      <td>13584</td>\n",
       "      <td>murder-suicide</td>\n",
       "      <td>2000</td>\n",
       "      <td>divine-empire</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13585</th>\n",
       "      <td>13585</td>\n",
       "      <td>war-torn</td>\n",
       "      <td>2000</td>\n",
       "      <td>divine-empire</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357796</th>\n",
       "      <td>357796</td>\n",
       "      <td>all-she-wants-to-do-is-dance</td>\n",
       "      <td>2000</td>\n",
       "      <td>the-eagles</td>\n",
       "      <td>Rock</td>\n",
       "      <td>They're picking up the prisoners\\nand putting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357797</th>\n",
       "      <td>357797</td>\n",
       "      <td>born-to-boogie</td>\n",
       "      <td>2000</td>\n",
       "      <td>the-eagles</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357798</th>\n",
       "      <td>357798</td>\n",
       "      <td>long-run-leftovers</td>\n",
       "      <td>2000</td>\n",
       "      <td>the-eagles</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I used to hurry a lot, I used to worry a lot,\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357799</th>\n",
       "      <td>357799</td>\n",
       "      <td>random-victims-part-3</td>\n",
       "      <td>2000</td>\n",
       "      <td>the-eagles</td>\n",
       "      <td>Rock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357800</th>\n",
       "      <td>357800</td>\n",
       "      <td>wasted-time-reprise</td>\n",
       "      <td>2000</td>\n",
       "      <td>the-eagles</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Well baby, there you stand\\nWith your little h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1722 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                          song  year         artist  genre  \\\n",
       "13581    13581                self-inflicted  2000  divine-empire  Metal   \n",
       "13582    13582              birth-of-legends  2000  divine-empire  Metal   \n",
       "13583    13583             dead-and-martyred  2000  divine-empire  Metal   \n",
       "13584    13584                murder-suicide  2000  divine-empire  Metal   \n",
       "13585    13585                      war-torn  2000  divine-empire  Metal   \n",
       "...        ...                           ...   ...            ...    ...   \n",
       "357796  357796  all-she-wants-to-do-is-dance  2000     the-eagles   Rock   \n",
       "357797  357797                born-to-boogie  2000     the-eagles   Rock   \n",
       "357798  357798            long-run-leftovers  2000     the-eagles   Rock   \n",
       "357799  357799         random-victims-part-3  2000     the-eagles   Rock   \n",
       "357800  357800           wasted-time-reprise  2000     the-eagles   Rock   \n",
       "\n",
       "                                                   lyrics  \n",
       "13581                                                 NaN  \n",
       "13582                                                 NaN  \n",
       "13583                                                 NaN  \n",
       "13584                                                 NaN  \n",
       "13585                                                 NaN  \n",
       "...                                                   ...  \n",
       "357796  They're picking up the prisoners\\nand putting ...  \n",
       "357797                                                NaN  \n",
       "357798  I used to hurry a lot, I used to worry a lot,\\...  \n",
       "357799                                                NaN  \n",
       "357800  Well baby, there you stand\\nWith your little h...  \n",
       "\n",
       "[1722 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data[lyrics_data.year == 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403678689"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(INPUT_FILE_PATH).memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 362237 entries, 0 to 362236\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   index   362237 non-null  int64 \n",
      " 1   song    362235 non-null  object\n",
      " 2   year    362237 non-null  int64 \n",
      " 3   artist  362237 non-null  object\n",
      " 4   genre   362237 non-null  object\n",
      " 5   lyrics  266557 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 385.0 MB\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(INPUT_FILE_PATH).info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 387346 entries, 0 to 387345\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  387344 non-null  object\n",
      " 1   0           387346 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 225.0 MB\n"
     ]
    }
   ],
   "source": [
    "pd.read_csv(BOW_PATH).info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.bigram_count[('big','big')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.bigram_count[('like','like')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('like', 0.0008430433627650935)\n"
     ]
    }
   ],
   "source": [
    "bigram_potential_next_words = [(k[1], tf_idf.bigram_count[k]/len(tf_idf.bigram_count.keys())) for k in tf_idf.bigram_count.keys() if k[0]=='like']\n",
    "best_candidate = ('', 0)\n",
    "for word, proba in bigram_potential_next_words:\n",
    "    if proba > best_candidate[1]:\n",
    "        best_candidate = (word, proba)\n",
    "print(best_candidate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('deal', 2.4001661149114066e-06)\n"
     ]
    }
   ],
   "source": [
    "trigram_potential_next_words = [(k[2], tf_idf.trigram_count[k]/len(tf_idf.trigram_count.keys())) for k in tf_idf.trigram_count.keys() if k[0]=='like' and  k[1]=='big']\n",
    "best_candidate_tri = ('', 0)\n",
    "for word, proba in trigram_potential_next_words:\n",
    "    if proba > best_candidate_tri[1]:\n",
    "        best_candidate_tri = (word, proba)\n",
    "print(best_candidate_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_potential_words = [tf_idf.bigram_count[k] for k in tf_idf.bigram_count.keys() if k[0]=='like']\n",
    "for word in bi_potential_words:\n",
    "\n",
    "tri_potential_words = [tf_idf.trigram_count[k] for k in tf_idf.trigram_count.keys() if k[0]=='like' and k[1]=='big']\n",
    "# search_key = (\"like\", \"big\")\n",
    "# tri_potential_words = [value for key, value in tf_idf.trigram_count.items() if search_key == key[:len(search_key)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('deal', 405),\n",
       " ('wide', 75),\n",
       " ('ego', 49),\n",
       " ('must', 6),\n",
       " ('crew', 7),\n",
       " ('good', 7),\n",
       " ('girl', 255),\n",
       " ('bodi', 121),\n",
       " ('meet', 14),\n",
       " ('ballin', 43),\n",
       " ('end', 11),\n",
       " ('time', 516),\n",
       " ('gun', 222),\n",
       " ('kiss', 38),\n",
       " ('homi', 108),\n",
       " ('littl', 55),\n",
       " ('ball', 119),\n",
       " ('bill', 39),\n",
       " ('ass', 233),\n",
       " ('butt', 77),\n",
       " ('man', 448),\n",
       " ('titi', 4),\n",
       " ('lick', 5),\n",
       " ('dog', 167),\n",
       " ('dogg', 7),\n",
       " ('boy', 556),\n",
       " ('said', 28),\n",
       " ('stuff', 14),\n",
       " ('drum', 20),\n",
       " ('step', 27),\n",
       " ('mistak', 426),\n",
       " ('ya', 14),\n",
       " ('paper', 15),\n",
       " ('black', 437),\n",
       " ('daddi', 272),\n",
       " ('bright', 81),\n",
       " ('head', 112),\n",
       " ('collar', 1),\n",
       " ('grief', 1),\n",
       " ('love', 152),\n",
       " ('breast', 28),\n",
       " ('let', 24),\n",
       " ('oooooo', 1),\n",
       " ('ten', 12),\n",
       " ('buck', 47),\n",
       " ('relief', 5),\n",
       " ('discrac', 2),\n",
       " ('armi', 2),\n",
       " ('big', 704),\n",
       " ('citi', 522),\n",
       " ('brother', 239),\n",
       " ('enough', 397),\n",
       " ('bigger', 17),\n",
       " ('star', 172),\n",
       " ('pot', 9),\n",
       " ('digit', 2),\n",
       " ('word', 65),\n",
       " ('small', 119),\n",
       " ('smile', 100),\n",
       " ('mama', 33),\n",
       " ('freak', 20),\n",
       " ('sort', 2),\n",
       " ('seem', 2),\n",
       " ('evil', 2),\n",
       " ('mansion', 17),\n",
       " ('plan', 122),\n",
       " ('everi', 17),\n",
       " ('forti', 4),\n",
       " ('red', 187),\n",
       " ('flash', 3),\n",
       " ('hous', 265),\n",
       " ('size', 12),\n",
       " ('muscl', 6),\n",
       " ('oak', 26),\n",
       " ('mad', 10),\n",
       " ('compani', 3),\n",
       " ('drink', 12),\n",
       " ('stage', 13),\n",
       " ('di', 15),\n",
       " ('shoot', 3),\n",
       " ('heart', 101),\n",
       " ('grin', 16),\n",
       " ('walk', 29),\n",
       " ('bulki', 2),\n",
       " ('budget', 5),\n",
       " ('phuck', 1),\n",
       " ('name', 28),\n",
       " ('wheel', 242),\n",
       " ('countri', 31),\n",
       " ('disgrac', 39),\n",
       " ('fuck', 63),\n",
       " ('disappoint', 4),\n",
       " ('threat', 13),\n",
       " ('come', 16),\n",
       " ('fat', 411),\n",
       " ('napkin', 1),\n",
       " ('mess', 58),\n",
       " ('machin', 72),\n",
       " ('bad', 482),\n",
       " ('kill', 7),\n",
       " ('plate', 11),\n",
       " ('glass', 14),\n",
       " ('rock', 76),\n",
       " ('test', 9),\n",
       " ('hand', 80),\n",
       " ('high', 12),\n",
       " ('go', 44),\n",
       " ('thing', 286),\n",
       " ('trunk', 10),\n",
       " ('club', 9),\n",
       " ('drunk', 1),\n",
       " ('day', 67),\n",
       " ('war', 14),\n",
       " ('social', 21),\n",
       " ('scene', 51),\n",
       " ('spender', 71),\n",
       " ('tdo', 2),\n",
       " ('strong', 104),\n",
       " ('hors', 27),\n",
       " ('storm', 11),\n",
       " ('companion', 1),\n",
       " ('solitud', 1),\n",
       " ('beat', 104),\n",
       " ('break', 34),\n",
       " ('busi', 88),\n",
       " ('bite', 17),\n",
       " ('brown', 148),\n",
       " ('oomp', 2),\n",
       " ('clay', 1),\n",
       " ('ol', 307),\n",
       " ('blunt', 26),\n",
       " ('camera', 2),\n",
       " ('support', 4),\n",
       " ('fan', 43),\n",
       " ('blue', 246),\n",
       " ('dark', 23),\n",
       " ('happi', 28),\n",
       " ('appetit', 3),\n",
       " ('stark', 1),\n",
       " ('yellow', 40),\n",
       " ('move', 23),\n",
       " ('krit', 67),\n",
       " ('show', 53),\n",
       " ('live', 9),\n",
       " ('cat', 42),\n",
       " ('mon', 2),\n",
       " ('belli', 37),\n",
       " ('bwoy', 1),\n",
       " ('pussi', 12),\n",
       " ('ask', 2),\n",
       " ('face', 132),\n",
       " ('commot', 10),\n",
       " ('would', 23),\n",
       " ('fire', 15),\n",
       " ('feet', 27),\n",
       " ('pick', 3),\n",
       " ('heat', 7),\n",
       " ('idea', 83),\n",
       " ('bucket', 6),\n",
       " ('leagu', 34),\n",
       " ('voic', 2),\n",
       " ('crowd', 22),\n",
       " ('dump', 8),\n",
       " ('bomb', 10),\n",
       " ('tall', 53),\n",
       " ('clock', 5),\n",
       " ('horni', 1),\n",
       " ('bird', 119),\n",
       " ('surpris', 165),\n",
       " ('gorilla', 8),\n",
       " ('taller', 1),\n",
       " ('marqui', 1),\n",
       " ('bull', 5),\n",
       " ('dream', 200),\n",
       " ('long', 66),\n",
       " ('chanc', 59),\n",
       " ('two', 14),\n",
       " ('letter', 13),\n",
       " ('space', 4),\n",
       " ('financi', 1),\n",
       " ('pictur', 95),\n",
       " ('whale', 20),\n",
       " ('affair', 25),\n",
       " ('bulldoz', 3),\n",
       " ('goliath', 4),\n",
       " ('tear', 34),\n",
       " ('parad', 41),\n",
       " ('bank', 87),\n",
       " ('hole', 57),\n",
       " ('papa', 3),\n",
       " ('gon', 14),\n",
       " ('mind', 8),\n",
       " ('talent', 1),\n",
       " ('dipper', 78),\n",
       " ('gipper', 1),\n",
       " ('fish', 84),\n",
       " ('appl', 63),\n",
       " ('joyrid', 4),\n",
       " ('got', 68),\n",
       " ('game', 68),\n",
       " ('fun', 102),\n",
       " ('lincoln', 5),\n",
       " ('pant', 13),\n",
       " ('snoop', 29),\n",
       " ('rufu', 4),\n",
       " ('thought', 13),\n",
       " ('fade', 7),\n",
       " ('cock', 25),\n",
       " ('pain', 8),\n",
       " ('file', 1),\n",
       " ('crawl', 3),\n",
       " ('respond', 1),\n",
       " ('dick', 197),\n",
       " ('motherfuckin', 9),\n",
       " ('tip', 9),\n",
       " ('doofi', 1),\n",
       " ('die', 11),\n",
       " ('crime', 17),\n",
       " ('cent', 1),\n",
       " ('pac', 48),\n",
       " ('nigga', 93),\n",
       " ('style', 8),\n",
       " ('pdiddi', 1),\n",
       " ('chri', 3),\n",
       " ('back', 19),\n",
       " ('smoke', 21),\n",
       " ('rap', 11),\n",
       " ('mine', 4),\n",
       " ('bread', 18),\n",
       " ('palm', 4),\n",
       " ('white', 126),\n",
       " ('king', 13),\n",
       " ('bitch', 42),\n",
       " ('heavi', 18),\n",
       " ('stupid', 8),\n",
       " ('could', 37),\n",
       " ('bag', 88),\n",
       " ('implant', 1),\n",
       " ('geni', 1),\n",
       " ('hell', 13),\n",
       " ('fofo', 2),\n",
       " ('chest', 17),\n",
       " ('rip', 9),\n",
       " ('first', 13),\n",
       " ('screen', 118),\n",
       " ('pun', 127),\n",
       " ('convinc', 1),\n",
       " ('thick', 11),\n",
       " ('four', 18),\n",
       " ('chrome', 8),\n",
       " ('hit', 63),\n",
       " ('like', 108),\n",
       " ('tigga', 10),\n",
       " ('eleph', 3),\n",
       " ('hoe', 7),\n",
       " ('men', 27),\n",
       " ('brooklyn', 4),\n",
       " ('world', 204),\n",
       " ('jewel', 5),\n",
       " ('money', 333),\n",
       " ('flashin', 2),\n",
       " ('searg', 1),\n",
       " ('von', 1),\n",
       " ('better', 6),\n",
       " ('year', 5),\n",
       " ('reput', 2),\n",
       " ('morn', 1),\n",
       " ('notori', 2),\n",
       " ('shot', 200),\n",
       " ('thang', 28),\n",
       " ('top', 44),\n",
       " ('ben', 41),\n",
       " ('strap', 11),\n",
       " ('bankrol', 3),\n",
       " ('hip', 10),\n",
       " ('tit', 31),\n",
       " ('type', 8),\n",
       " ('rich', 31),\n",
       " ('risk', 5),\n",
       " ('win', 2),\n",
       " ('rosco', 1),\n",
       " ('watch', 7),\n",
       " ('bentley', 3),\n",
       " ('green', 51),\n",
       " ('part', 32),\n",
       " ('see', 19),\n",
       " ('willi', 41),\n",
       " ('bat', 6),\n",
       " ('strictli', 1),\n",
       " ('chip', 24),\n",
       " ('trip', 6),\n",
       " ('vers', 13),\n",
       " ('tidal', 1),\n",
       " ('gram', 1),\n",
       " ('tash', 2),\n",
       " ('look', 25),\n",
       " ('continent', 1),\n",
       " ('beast', 2),\n",
       " ('nt', 72),\n",
       " ('bang', 291),\n",
       " ('bouquet', 22),\n",
       " ('ocean', 8),\n",
       " ('knock', 9),\n",
       " ('sign', 16),\n",
       " ('orang', 9),\n",
       " ('outhous', 1),\n",
       " ('ride', 15),\n",
       " ('bring', 2),\n",
       " ('boi', 52),\n",
       " ('boodi', 2),\n",
       " ('old', 370),\n",
       " ('plateau', 1),\n",
       " ('purpl', 5),\n",
       " ('ici', 1),\n",
       " ('pimp', 37),\n",
       " ('pump', 2),\n",
       " ('escalad', 2),\n",
       " ('foot', 14),\n",
       " ('ole', 110),\n",
       " ('circu', 1),\n",
       " ('fine', 40),\n",
       " ('lone', 11),\n",
       " ('town', 103),\n",
       " ('crush', 22),\n",
       " ('decis', 71),\n",
       " ('cash', 15),\n",
       " ('differ', 23),\n",
       " ('suit', 4),\n",
       " ('magnet', 2),\n",
       " ('box', 13),\n",
       " ('sting', 2),\n",
       " ('lie', 72),\n",
       " ('mouth', 197),\n",
       " ('birthday', 5),\n",
       " ('sky', 138),\n",
       " ('rush', 9),\n",
       " ('flame', 6),\n",
       " ('alway', 7),\n",
       " ('never', 27),\n",
       " ('wan', 8),\n",
       " ('fri', 3),\n",
       " ('guy', 46),\n",
       " ('refriger', 1),\n",
       " ('tree', 48),\n",
       " ('mann', 1),\n",
       " ('bimbo', 1),\n",
       " ('colleg', 3),\n",
       " ('three', 5),\n",
       " ('revolv', 3),\n",
       " ('revu', 1),\n",
       " ('fake', 8),\n",
       " ('balloon', 29),\n",
       " ('kite', 36),\n",
       " ('sea', 57),\n",
       " ('bundl', 13),\n",
       " ('wild', 4),\n",
       " ('sound', 163),\n",
       " ('oh', 19),\n",
       " ('fight', 49),\n",
       " ('leg', 41),\n",
       " ('car', 127),\n",
       " ('wind', 28),\n",
       " ('mean', 9),\n",
       " ('impress', 12),\n",
       " ('one', 212),\n",
       " ('wave', 19),\n",
       " ('shark', 6),\n",
       " ('finger', 3),\n",
       " ('sur', 30),\n",
       " ('ventana', 1),\n",
       " ('broken', 2),\n",
       " ('share', 2),\n",
       " ('true', 1),\n",
       " ('ensu', 3),\n",
       " ('intellectu', 1),\n",
       " ('boat', 44),\n",
       " ('sure', 7),\n",
       " ('kin', 1),\n",
       " ('pokey', 13),\n",
       " ('podeina', 1),\n",
       " ('poke', 1),\n",
       " ('shit', 78),\n",
       " ('un', 5),\n",
       " ('desk', 6),\n",
       " ('mac', 67),\n",
       " ('invas', 1),\n",
       " ('line', 20),\n",
       " ('alsat', 1),\n",
       " ('light', 53),\n",
       " ('book', 7),\n",
       " ('ladi', 10),\n",
       " ('burnt', 1),\n",
       " ('magic', 1),\n",
       " ('meltdown', 1),\n",
       " ('night', 56),\n",
       " ('waterb', 1),\n",
       " ('sin', 6),\n",
       " ('hotel', 33),\n",
       " ('make', 40),\n",
       " ('mula', 1),\n",
       " ('joe', 39),\n",
       " ('rapper', 8),\n",
       " ('tryna', 3),\n",
       " ('yeah', 31),\n",
       " ('chain', 102),\n",
       " ('ima', 6),\n",
       " ('email', 1),\n",
       " ('ceremoni', 2),\n",
       " ('sam', 8),\n",
       " ('nugget', 10),\n",
       " ('cake', 10),\n",
       " ('lump', 8),\n",
       " ('kipper', 2),\n",
       " ('bowl', 13),\n",
       " ('bee', 4),\n",
       " ('mo', 12),\n",
       " ('freight', 3),\n",
       " ('si', 6),\n",
       " ('ni', 1),\n",
       " ('nia', 1),\n",
       " ('pauli', 1),\n",
       " ('sensat', 10),\n",
       " ('max', 6),\n",
       " ('sex', 5),\n",
       " ('want', 24),\n",
       " ('engin', 4),\n",
       " ('zoowap', 18),\n",
       " ('troubl', 39),\n",
       " ('diamond', 35),\n",
       " ('bro', 36),\n",
       " ('knot', 15),\n",
       " ('glock', 10),\n",
       " ('benz', 13),\n",
       " ('buy', 4),\n",
       " ('band', 29),\n",
       " ('job', 9),\n",
       " ('tough', 30),\n",
       " ('respect', 11),\n",
       " ('check', 22),\n",
       " ('scott', 1),\n",
       " ('guru', 2),\n",
       " ('cigar', 38),\n",
       " ('poppa', 31),\n",
       " ('wearin', 2),\n",
       " ('timer', 22),\n",
       " ('plot', 3),\n",
       " ('beard', 8),\n",
       " ('stop', 4),\n",
       " ('cia', 6),\n",
       " ('nois', 83),\n",
       " ('trick', 4),\n",
       " ('uhuh', 3),\n",
       " ('bubbl', 9),\n",
       " ('thump', 1),\n",
       " ('momma', 17),\n",
       " ('nose', 36),\n",
       " ('bounci', 4),\n",
       " ('display', 2),\n",
       " ('larg', 6),\n",
       " ('plastic', 3),\n",
       " ('round', 59),\n",
       " ('couchi', 1),\n",
       " ('realli', 10),\n",
       " ('hh', 1),\n",
       " ('noser', 1),\n",
       " ('kilo', 1),\n",
       " ('booti', 234),\n",
       " ('bass', 25),\n",
       " ('bean', 21),\n",
       " ('bunyon', 1),\n",
       " ('blare', 1),\n",
       " ('prob', 1),\n",
       " ('choppa', 7),\n",
       " ('beef', 5),\n",
       " ('mysteri', 11),\n",
       " ('guess', 7),\n",
       " ('bowwow', 1),\n",
       " ('explos', 21),\n",
       " ('loud', 19),\n",
       " ('easi', 9),\n",
       " ('excus', 5),\n",
       " ('poss', 3),\n",
       " ('goo', 1),\n",
       " ('bob', 2),\n",
       " ('influenc', 2),\n",
       " ('also', 2),\n",
       " ('along', 3),\n",
       " ('jam', 3),\n",
       " ('shane', 1),\n",
       " ('california', 3),\n",
       " ('lbc', 2),\n",
       " ('suge', 2),\n",
       " ('gulp', 9),\n",
       " ('thigh', 8),\n",
       " ('seeeo', 1),\n",
       " ('buddha', 3),\n",
       " ('buff', 2),\n",
       " ('battlefield', 1),\n",
       " ('coolaid', 2),\n",
       " ('babi', 103),\n",
       " ('still', 10),\n",
       " ('prop', 3),\n",
       " ('aluminum', 1),\n",
       " ('even', 7),\n",
       " ('beauti', 25),\n",
       " ('kid', 71),\n",
       " ('forehead', 5),\n",
       " ('choic', 2),\n",
       " ('search', 1),\n",
       " ('wall', 17),\n",
       " ('doubl', 5),\n",
       " ('bed', 69),\n",
       " ('global', 2),\n",
       " ('jbird', 2),\n",
       " ('wrist', 2),\n",
       " ('bless', 4),\n",
       " ('believ', 3),\n",
       " ('shop', 4),\n",
       " ('actual', 1),\n",
       " ('empti', 12),\n",
       " ('bassoon', 3),\n",
       " ('tricki', 1),\n",
       " ('gold', 26),\n",
       " ('texa', 15),\n",
       " ('fanci', 14),\n",
       " ('burn', 7),\n",
       " ('virgin', 1),\n",
       " ('villfredo', 1),\n",
       " ('get', 110),\n",
       " ('dust', 1),\n",
       " ('blow', 20),\n",
       " ('overdos', 5),\n",
       " ('door', 23),\n",
       " ('arena', 1),\n",
       " ('today', 6),\n",
       " ('caus', 25),\n",
       " ('know', 32),\n",
       " ('favor', 8),\n",
       " ('speckl', 2),\n",
       " ('barn', 3),\n",
       " ('chock', 1),\n",
       " ('proud', 2),\n",
       " ('right', 12),\n",
       " ('ahhhhh', 1),\n",
       " ('way', 47),\n",
       " ('pound', 1),\n",
       " ('dig', 21),\n",
       " ('alleyway', 1),\n",
       " ('moneymak', 1),\n",
       " ('riddl', 1),\n",
       " ('behind', 13),\n",
       " ('mick', 1),\n",
       " ('marc', 2),\n",
       " ('gondola', 2),\n",
       " ('malais', 3),\n",
       " ('scar', 13),\n",
       " ('pile', 16),\n",
       " ('dumb', 21),\n",
       " ('chill', 3),\n",
       " ('heel', 2),\n",
       " ('ai', 43),\n",
       " ('charm', 1),\n",
       " ('spoiler', 1),\n",
       " ('home', 28),\n",
       " ('diparr', 2),\n",
       " ('crib', 20),\n",
       " ('rim', 35),\n",
       " ('televis', 1),\n",
       " ('ca', 33),\n",
       " ('treason', 1),\n",
       " ('cage', 6),\n",
       " ('fairytal', 7),\n",
       " ('desir', 7),\n",
       " ('crash', 27),\n",
       " ('yo', 11),\n",
       " ('slow', 2),\n",
       " ('fair', 2),\n",
       " ('whole', 6),\n",
       " ('hard', 23),\n",
       " ('practic', 1),\n",
       " ('outro', 2),\n",
       " ('sid', 2),\n",
       " ('twan', 1),\n",
       " ('straight', 5),\n",
       " ('ayo', 2),\n",
       " ('onethreenin', 1),\n",
       " ('comin', 5),\n",
       " ('drop', 4),\n",
       " ('corleon', 8),\n",
       " ('lee', 13),\n",
       " ('real', 12),\n",
       " ('pimpedout', 2),\n",
       " ('wo', 3),\n",
       " ('yall', 10),\n",
       " ('lightin', 1),\n",
       " ('fuckin', 26),\n",
       " ('stick', 40),\n",
       " ('onetwo', 1),\n",
       " ('bout', 4),\n",
       " ('tire', 7),\n",
       " ('joey', 5),\n",
       " ('repeat', 4),\n",
       " ('steal', 1),\n",
       " ('toe', 30),\n",
       " ('goe', 3),\n",
       " ('takin', 2),\n",
       " ('mymymymi', 5),\n",
       " ('mc', 1),\n",
       " ('holdin', 1),\n",
       " ('goin', 9),\n",
       " ('rondel', 1),\n",
       " ('rocafella', 1),\n",
       " ('harlem', 1),\n",
       " ('park', 6),\n",
       " ('cold', 7),\n",
       " ('danger', 1),\n",
       " ('betta', 1),\n",
       " ('worrrd', 1),\n",
       " ('flamboy', 1),\n",
       " ('uhh', 1),\n",
       " ('put', 23),\n",
       " ('loss', 10),\n",
       " ('crazi', 5),\n",
       " ('fella', 35),\n",
       " ('villain', 2),\n",
       " ('runnin', 2),\n",
       " ('cmon', 3),\n",
       " ('truck', 82),\n",
       " ('uh', 4),\n",
       " ('yea', 1),\n",
       " ('new', 20),\n",
       " ('ctown', 1),\n",
       " ('life', 33),\n",
       " ('stand', 11),\n",
       " ('schedul', 10),\n",
       " ('other', 3),\n",
       " ('hollywood', 1),\n",
       " ('talk', 51),\n",
       " ('soul', 6),\n",
       " ('danc', 12),\n",
       " ('muddi', 15),\n",
       " ('mike', 34),\n",
       " ('famili', 54),\n",
       " ('kick', 5),\n",
       " ('sheet', 2),\n",
       " ('rodeo', 24),\n",
       " ('railroad', 3),\n",
       " ('cemeteri', 1),\n",
       " ('pretti', 17),\n",
       " ('boss', 139),\n",
       " ('mountain', 11),\n",
       " ('mangl', 1),\n",
       " ('heartbreak', 1),\n",
       " ('trophi', 2),\n",
       " ('success', 15),\n",
       " ('brick', 9),\n",
       " ('spring', 3),\n",
       " ('tattoo', 5),\n",
       " ('hot', 7),\n",
       " ('thrill', 13),\n",
       " ('main', 2),\n",
       " ('oil', 4),\n",
       " ('parti', 71),\n",
       " ('hunk', 16),\n",
       " ('talli', 1),\n",
       " ('son', 5),\n",
       " ('laugh', 14),\n",
       " ('peopl', 36),\n",
       " ('straw', 7),\n",
       " ('roof', 1),\n",
       " ('sad', 6),\n",
       " ('arm', 13),\n",
       " ('guitar', 14),\n",
       " ('redneck', 2),\n",
       " ('talkin', 10),\n",
       " ('took', 4),\n",
       " ('swig', 4),\n",
       " ('wig', 10),\n",
       " ('problem', 40),\n",
       " ('hope', 10),\n",
       " ('bluff', 1),\n",
       " ('frame', 5),\n",
       " ('secret', 27),\n",
       " ('fall', 11),\n",
       " ('safe', 2),\n",
       " ('beam', 1),\n",
       " ('jet', 38),\n",
       " ('freedom', 1),\n",
       " ('invest', 1),\n",
       " ('liar', 13),\n",
       " ('eightwheel', 6),\n",
       " ('tri', 7),\n",
       " ('net', 1),\n",
       " ('killa', 3),\n",
       " ('titti', 33),\n",
       " ('movi', 15),\n",
       " ('duck', 4),\n",
       " ('policeman', 6),\n",
       " ('catfish', 3),\n",
       " ('churn', 1),\n",
       " ('romanc', 7),\n",
       " ('stiff', 2),\n",
       " ('full', 8),\n",
       " ('needl', 1),\n",
       " ('whatev', 1),\n",
       " ('shini', 26),\n",
       " ('cartoon', 1),\n",
       " ('martini', 4),\n",
       " ('demand', 11),\n",
       " ('aeh', 1),\n",
       " ('murder', 1),\n",
       " ('point', 3),\n",
       " ('sale', 1),\n",
       " ('mail', 4),\n",
       " ('boot', 26),\n",
       " ('joke', 14),\n",
       " ('gat', 25),\n",
       " ('trump', 1),\n",
       " ('mistakethos', 1),\n",
       " ('skapunk', 1),\n",
       " ('reunion', 1),\n",
       " ('cricket', 1),\n",
       " ('hater', 10),\n",
       " ('happen', 1),\n",
       " ('payback', 49),\n",
       " ('cast', 2),\n",
       " ('rod', 2),\n",
       " ('bump', 4),\n",
       " ('blood', 11),\n",
       " ('dough', 17),\n",
       " ('hustler', 2),\n",
       " ('bet', 4),\n",
       " ('benjamin', 4),\n",
       " ('call', 15),\n",
       " ('bone', 33),\n",
       " ('bullet', 5),\n",
       " ('baller', 25),\n",
       " ('shotgun', 3),\n",
       " ('walli', 1),\n",
       " ('thug', 5),\n",
       " ('claim', 1),\n",
       " ('grimi', 1),\n",
       " ('shell', 8),\n",
       " ('wish', 6),\n",
       " ('layzi', 1),\n",
       " ('till', 2),\n",
       " ('rig', 26),\n",
       " ('store', 3),\n",
       " ('hall', 7),\n",
       " ('eazi', 1),\n",
       " ('maze', 1),\n",
       " ('control', 3),\n",
       " ('hunch', 2),\n",
       " ('pier', 1),\n",
       " ('fear', 2),\n",
       " ('welcom', 3),\n",
       " ('sleeper', 4),\n",
       " ('room', 18),\n",
       " ('slap', 3),\n",
       " ('ooh', 13),\n",
       " ('threw', 1),\n",
       " ('rough', 5),\n",
       " ('bounti', 2),\n",
       " ('john', 21),\n",
       " ('confid', 1),\n",
       " ('dive', 2),\n",
       " ('feather', 12),\n",
       " ('jackson', 2),\n",
       " ('contradict', 3),\n",
       " ('diss', 2),\n",
       " ('delight', 4),\n",
       " ('grip', 6),\n",
       " ('tv', 10),\n",
       " ('businessman', 1),\n",
       " ('raygun', 1),\n",
       " ('steeli', 1),\n",
       " ('shrink', 2),\n",
       " ('wellbr', 1),\n",
       " ('corpor', 7),\n",
       " ('hero', 5),\n",
       " ('clubhous', 1),\n",
       " ('seen', 2),\n",
       " ('metal', 1),\n",
       " ('wast', 12),\n",
       " ('lawsuit', 1),\n",
       " ('chino', 3),\n",
       " ('punish', 73),\n",
       " ('ye', 9),\n",
       " ('freeway', 8),\n",
       " ('jesu', 18),\n",
       " ('shoe', 29),\n",
       " ('noth', 26),\n",
       " ('summertim', 1),\n",
       " ('chief', 28),\n",
       " ('imagin', 2),\n",
       " ('nurs', 1),\n",
       " ('affect', 1),\n",
       " ('pretend', 7),\n",
       " ('sister', 41),\n",
       " ('hide', 19),\n",
       " ('dress', 4),\n",
       " ('eddi', 1),\n",
       " ('street', 6),\n",
       " ('reed', 1),\n",
       " ('deep', 10),\n",
       " ('adolesc', 2),\n",
       " ('marri', 2),\n",
       " ('dollar', 12),\n",
       " ('teaser', 8),\n",
       " ('emili', 1),\n",
       " ('what', 3),\n",
       " ('jim', 36),\n",
       " ('melon', 1),\n",
       " ('smelt', 1),\n",
       " ('beer', 7),\n",
       " ('held', 1),\n",
       " ('take', 23),\n",
       " ('chick', 5),\n",
       " ('footstep', 3),\n",
       " ('raccoon', 1),\n",
       " ('push', 8),\n",
       " ('banner', 2),\n",
       " ('remo', 2),\n",
       " ('ditch', 1),\n",
       " ('dickin', 1),\n",
       " ('cadillac', 19),\n",
       " ('troop', 1),\n",
       " ('bun', 17),\n",
       " ('siegel', 1),\n",
       " ('stack', 28),\n",
       " ('tenfour', 3),\n",
       " ('dish', 3),\n",
       " ('detroit', 9),\n",
       " ('pyramid', 2),\n",
       " ('pigpen', 1),\n",
       " ('convoy', 6),\n",
       " ('ice', 14),\n",
       " ('fool', 47),\n",
       " ('cri', 10),\n",
       " ('semi', 3),\n",
       " ('lab', 1),\n",
       " ('aw', 5),\n",
       " ('strappin', 1),\n",
       " ('mr', 14),\n",
       " ('liquid', 4),\n",
       " ('turn', 3),\n",
       " ('stone', 29),\n",
       " ('race', 6),\n",
       " ('kind', 2),\n",
       " ('disguis', 5),\n",
       " ('think', 17),\n",
       " ('worm', 7),\n",
       " ('zap', 2),\n",
       " ('pub', 2),\n",
       " ('methink', 2),\n",
       " ('pimpin', 53),\n",
       " ('link', 2),\n",
       " ('rhyme', 2),\n",
       " ('illinoi', 1),\n",
       " ('bootay', 2),\n",
       " ('wear', 2),\n",
       " ('ticket', 4),\n",
       " ('hat', 15),\n",
       " ('ms', 2),\n",
       " ('bahama', 1),\n",
       " ('fam', 8),\n",
       " ('piec', 27),\n",
       " ('tollgat', 3),\n",
       " ('grizzli', 3),\n",
       " ('cloud', 13),\n",
       " ('rel', 1),\n",
       " ('mix', 3),\n",
       " ('lip', 26),\n",
       " ('switch', 2),\n",
       " ('solo', 3),\n",
       " ('wy', 3),\n",
       " ('knew', 4),\n",
       " ('diddi', 1),\n",
       " ('fate', 3),\n",
       " ('fa', 1),\n",
       " ('cube', 4),\n",
       " ('britch', 8),\n",
       " ('woman', 19),\n",
       " ('cousin', 9),\n",
       " ('sean', 131),\n",
       " ('dead', 6),\n",
       " ('roll', 12),\n",
       " ('puff', 2),\n",
       " ('phantom', 1),\n",
       " ('made', 3),\n",
       " ('meech', 17),\n",
       " ('ugk', 1),\n",
       " ('pocket', 6),\n",
       " ('radio', 4),\n",
       " ('pourin', 1),\n",
       " ('frogg', 1),\n",
       " ('nate', 3),\n",
       " ('mill', 2),\n",
       " ('spendin', 1),\n",
       " ('jar', 3),\n",
       " ('gee', 27),\n",
       " ('drove', 1),\n",
       " ('front', 11),\n",
       " ('weed', 5),\n",
       " ('dre', 2),\n",
       " ('sun', 16),\n",
       " ('dude', 16),\n",
       " ('brotha', 2),\n",
       " ('toy', 20),\n",
       " ('da', 4),\n",
       " ('gave', 1),\n",
       " ('promis', 12),\n",
       " ('miss', 8),\n",
       " ('certainli', 1),\n",
       " ('chicken', 4),\n",
       " ('boa', 2),\n",
       " ('automat', 2),\n",
       " ('raft', 1),\n",
       " ('window', 7),\n",
       " ('tune', 10),\n",
       " ('hello', 8),\n",
       " ('amount', 11),\n",
       " ('attract', 16),\n",
       " ('thinkin', 4),\n",
       " ('drag', 6),\n",
       " ('hair', 13),\n",
       " ('price', 7),\n",
       " ('disast', 5),\n",
       " ('team', 15),\n",
       " ('holla', 1),\n",
       " ('evrytim', 1),\n",
       " ('makin', 1),\n",
       " ('hang', 3),\n",
       " ('river', 44),\n",
       " ('batch', 1),\n",
       " ('eye', 98),\n",
       " ('jerri', 1),\n",
       " ('goodby', 8),\n",
       " ('cowtown', 1),\n",
       " ('harlan', 5),\n",
       " ('southern', 3),\n",
       " ('event', 6),\n",
       " ('eight', 2),\n",
       " ('wedg', 8),\n",
       " ('vein', 1),\n",
       " ('umbrella', 10),\n",
       " ('inna', 2),\n",
       " ('fast', 4),\n",
       " ('snapper', 2),\n",
       " ('yuh', 9),\n",
       " ('find', 2),\n",
       " ('bot', 1),\n",
       " ('baboon', 7),\n",
       " ('void', 4),\n",
       " ('human', 3),\n",
       " ('ship', 23),\n",
       " ('without', 6),\n",
       " ('horn', 19),\n",
       " ('wad', 2),\n",
       " ('question', 11),\n",
       " ('zero', 3),\n",
       " ('doubt', 4),\n",
       " ('spot', 6),\n",
       " ('tummi', 3),\n",
       " ('bern', 2),\n",
       " ('spart', 1),\n",
       " ('endors', 1),\n",
       " ('sweat', 2),\n",
       " ('ridg', 1),\n",
       " ('rumbl', 7),\n",
       " ('snake', 2),\n",
       " ('hug', 13),\n",
       " ('collab', 1),\n",
       " ('wrote', 1),\n",
       " ('weight', 12),\n",
       " ('set', 10),\n",
       " ('resurrect', 1),\n",
       " ('motor', 1),\n",
       " ('fatti', 1),\n",
       " ('spree', 1),\n",
       " ('pistol', 6),\n",
       " ('whip', 24),\n",
       " ('clip', 5),\n",
       " ('sinc', 4),\n",
       " ('bottl', 21),\n",
       " ('hold', 4),\n",
       " ('crack', 2),\n",
       " ('yacht', 11),\n",
       " ('giant', 4),\n",
       " ('bear', 15),\n",
       " ('lewi', 1),\n",
       " ('jump', 44),\n",
       " ('leather', 5),\n",
       " ('goddamn', 2),\n",
       " ('moon', 24),\n",
       " ('rifl', 1),\n",
       " ('sissi', 5),\n",
       " ('bike', 2),\n",
       " ('shabba', 1),\n",
       " ('speaker', 7),\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k[1], tf_idf.bigram_count[k]) for k in tf_idf.bigram_count.keys() if k[0]=='big']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "song #0 \n",
      "I hear people talk\n",
      "I see people walk\n",
      "They seem so out of touch\n",
      "I wanna get away so much\n",
      "All the clockwork toys\n",
      "Are making too much noise\n",
      "It's the machinery\n",
      "It's breaking down, oh can't you see\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "The picture doesn't change\n",
      "It's just a frozen frame\n",
      "I wanna break the ice\n",
      "I wanna go to paradise\n",
      "There is nowhere to hide\n",
      "I'll take you for a ride\n",
      "But not if you kiss and tell\n",
      "I don't mean on a carousel\n",
      "Won't you run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "One day I'm to say my\n",
      "Three wishes came true\n",
      "Till then I pretend I'm\n",
      "Escaping with you, you, you, you\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me\n",
      "Run runaway, run runaway\n",
      "Run runaway with me \n",
      "##################################################\n",
      "##################################################\n",
      "song #1 \n",
      "I always wanted you by my side\n",
      "I felt you we're my guide\n",
      "The one who showed me what's right\n",
      "I used to think that you we're my light\n",
      "And trusted in your smile\n",
      "But now you have decide\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runaway, runaway, runaway\n",
      "Everything is grey, miss you more each day\n",
      "Runaway, runaway, runaway\n",
      "I will find you, you'll never runaway\n",
      "I always wanted you by my side\n",
      "I felt you we're my guide\n",
      "The one who show me what's right\n",
      "I used to think that you we're my light\n",
      "And trusted in your smile\n",
      "But now you have decide\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runaway, runaway, runaway\n",
      "Everything is grey, miss you more each day\n",
      "Runaway, runaway, runaway\n",
      "I will find you, you'll never runaway\n",
      "I'm running now, I'm running away\n",
      "Searching for, searching for your smile\n",
      "Every hour I'm looking for you\n",
      "I'm looking for away, I'm looking for you\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runawaaaaay\n",
      "(Searching everyday, try to find your way)\n",
      "Oh baby, baby ... runawaaay\n",
      "Search \n",
      "##################################################\n",
      "##################################################\n",
      "song #2 \n",
      "I always wanted you by my side\n",
      "I felt you we're my guide\n",
      "The one who showed me what's right\n",
      "I used to think that you we're my light\n",
      "And trusted in your smile\n",
      "But now you have decide\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runaway, runaway, runaway\n",
      "Everything is grey, miss you more each day\n",
      "Runaway, runaway, runaway\n",
      "I will find you, you'll never runaway\n",
      "I always wanted you by my side\n",
      "I felt you we're my guide\n",
      "The one who show me what's right\n",
      "I used to think that you we're my light\n",
      "And trusted in your smile\n",
      "But now you have decide\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runaway, runaway, runaway\n",
      "Everything is grey, miss you more each day\n",
      "Runaway, runaway, runaway\n",
      "I will find you, you'll never runaway\n",
      "I'm running now, I'm running away\n",
      "Searching for, searching for your smile\n",
      "Every hour I'm looking for you\n",
      "I'm looking for away, I'm looking for you\n",
      "Runaway, runaway, runaway\n",
      "Searching everyday, try to find your way\n",
      "Runaway, runaway, runaway\n",
      "Wanna find you, oh baby wanna\n",
      "Runawaaaaay\n",
      "(Searching everyday, try to find your way)\n",
      "Oh baby, baby ... runawaaay\n",
      "Search \n",
      "##################################################\n",
      "##################################################\n",
      "song #3 \n",
      "She said she sad\n",
      "she sad she lonely\n",
      "lost in her room\n",
      "she mad she go\n",
      "she cry she smoke\n",
      "rosie in bloom\n",
      "she is so high\n",
      "she is so low\n",
      "day after day\n",
      "so\n",
      "she said she sad\n",
      "she sad she lonely\n",
      "open your eyes\n",
      "riding to rosie\n",
      "rosie sixteen\n",
      "rosie awakes in the morning\n",
      "riding to rosie\n",
      "where have you been\n",
      "rosie is sick of the weather\n",
      "long time no see\n",
      "long time no rosie\n",
      "I like to swim\n",
      "every now and then\n",
      "she swim she wet\n",
      "she out she dry\n",
      "play in the sand\n",
      "with a plastic boy\n",
      "riding to rosie\n",
      "rosie sixteen\n",
      "rosie is sick of the weather\n",
      "rinding to rosie\n",
      "where have you been\n",
      "rosie is never together\n",
      "she said she sad\n",
      "she said she lonely\n",
      "lost in her room\n",
      "she mad she go\n",
      "she cry she smoke\n",
      "rosie in bloom\n",
      "riding to rosie\n",
      "rosie sixteen\n",
      "rosie is sick of the weather\n",
      "riding to rosie\n",
      "where have you been\n",
      "rosie is never together \n",
      "##################################################\n",
      "##################################################\n",
      "song #4 \n",
      "On the other side of town lives a sabertooth tiger\n",
      "Paint's a real good picture, he's an excellent liar\n",
      "His mouth is full of sand and he's dying to meet you\n",
      "His mouth is full of sand he's just dying to meet you\n",
      "On the other side of town lives a sabertooth tiger\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back and you're shaking at the knees\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back, runaway from the beast\n",
      "Colder than an ice cube and faster than the fastest cheetah\n",
      "He's hiding in the kitchen he's a right brain eater\n",
      "His mouth is full of sand and he's dying to meet you\n",
      "His mouth is full of sand he's just dying to meet you\n",
      "On the other side of town lives a sabertooth tiger\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back and you're shaking at the knees\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back, runaway from the beast\n",
      "He's a sabertooth tiger\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back and you're shaking at the knees\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back and you're shaking at the knees\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back and you're shaking at the knees\n",
      "Runaway runaway runaway from the beast\n",
      "Got a bullet in your back, runaway from the beast \n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "for index, song in enumerate(pd.read_csv(INPUT_FILE_PATH,usecols = [5]).iloc[inner_product_top_k]['lyrics']):\n",
    "    sep = \"#\"*50\n",
    "    print(F\"{sep}\\nsong #{index} \\n{song} \\n{sep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd06d90c337e9f2db91fe7cf84780d0c362fe1853f02eb73d7a73b3447f64712c7a",
   "display_name": "Python 3.9.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "6d90c337e9f2db91fe7cf84780d0c362fe1853f02eb73d7a73b3447f64712c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}